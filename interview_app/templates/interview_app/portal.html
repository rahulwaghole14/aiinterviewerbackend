<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Interview Portal</title>
    {% load static %}
    <!-- Add Monaco Editor CDN -->
    <link rel="stylesheet" data-name="vs/editor/editor.main" href="https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.33.0/min/vs/editor/editor.main.css">
    <style>
        :root { 
            --primary-color: #667eea; 
            --primary-dark: #5a6fd8;
            --success-color: #28a745; 
            --danger-color: #dc3545; 
            --warning-color: #ffc107;
            --text-primary: #2c3e50;
            --text-secondary: #6c757d;
            --bg-primary: #f8f9fa;
            --bg-secondary: #ffffff;
            --border-color: #e9ecef;
            --shadow: 0 4px 20px rgba(0,0,0,0.1);
            --shadow-hover: 0 8px 30px rgba(0,0,0,0.15);
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body { 
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
            line-height: 1.6; 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: var(--text-primary);
        }
        
        .container { 
            width: 100%;
            max-width: 100%;
            margin: 0;
            padding: 20px;
            box-sizing: border-box;
        }
        
        .card { 
            background: var(--bg-secondary); 
            padding: 2.5rem; 
            border-radius: 20px; 
            box-shadow: var(--shadow);
            border: 1px solid var(--border-color);
            transition: all 0.3s ease;
        }
        
        .card:hover {
            box-shadow: var(--shadow-hover);
            transform: translateY(-2px);
        }
        
        h1, h2, h3 { 
            color: var(--text-primary); 
            margin-bottom: 1rem;
            font-weight: 600;
        }
        
        h1 {
            font-size: 2.5rem;
            background: linear-gradient(135deg, var(--primary-color), var(--primary-dark));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .btn { 
            display: inline-block; 
            padding: 12px 24px; 
            border-radius: 12px; 
            text-align: center; 
            cursor: pointer; 
            border: none; 
            font-size: 1rem; 
            font-weight: 600; 
            transition: all 0.3s ease;
            text-decoration: none;
            position: relative;
            overflow: hidden;
        }
        
        .btn:disabled { 
            background-color: #ccc; 
            cursor: not-allowed;
            transform: none !important;
        }
        
        .btn:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(0,0,0,0.2);
        }
        
        .submit-btn { 
            background: linear-gradient(135deg, var(--primary-color), var(--primary-dark)); 
            color: white; 
        }
        
        .done-btn { 
            background: linear-gradient(135deg, var(--success-color), #20c997); 
            color: white; 
            margin-top: 1rem; 
        }
        
        .cancel-btn { 
            background: linear-gradient(135deg, #6c757d, #495057); 
            color: white; 
        }
        
        .spoken-phase-layout { 
            display: flex;
            gap: 2rem;
            width: 100%;
            max-width: 1400px;
            margin: 0 auto;
            padding: 1.5rem 2rem;
            box-sizing: border-box;
            position: relative;
        }
        
        .interview-main { 
            background: var(--bg-secondary);
            border-radius: 20px;
            padding: 2rem;
            box-shadow: var(--shadow);
            flex: 1 1 65%;
            min-width: 600px;
            width: 100%;
            box-sizing: border-box;
        }
        
        .proctoring-sidebar { 
            background: var(--bg-secondary);
            border-radius: 20px;
            padding: 1.5rem;
            box-shadow: var(--shadow);
            flex: 0 0 360px;
            min-width: 320px;
            box-sizing: border-box;
            display: flex;
            flex-direction: column;
            gap: 1.5rem;
            position: sticky;
            top: 20px;
            height: fit-content;
        }
        
        /* Proctoring camera overlay - fixed mini monitor */
        .proctoring-overlay {
            position: fixed;
            top: 20px;
            right: 20px;
            width: 260px;
            min-height: 240px;
            background: var(--bg-secondary);
            border-radius: 16px;
            padding: 0.75rem;
            box-shadow: 0 12px 30px rgba(0, 0, 0, 0.35);
            z-index: 1000;
            display: flex;
            flex-direction: column;
            gap: 0.7rem;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .proctoring-overlay h3 {
            margin: 0;
            font-size: 0.8rem;
            color: var(--text-secondary);
            text-align: center;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }
        
        .proctoring-overlay .proctoring-feed-card {
            flex: 1;
            background: #111;
            border-radius: 10px;
            overflow: hidden;
            border: 1px solid rgba(0,0,0,0.25);
        }
        
        .proctoring-overlay .proctoring-feed-card img,
        .proctoring-overlay .proctoring-feed-card canvas {
            width: 100%;
            height: 170px;
            object-fit: cover;
            display: block;
        }
        
        .proctoring-overlay .overlay-warning {
            background: rgba(255, 255, 255, 0.06);
            border-radius: 10px;
            padding: 0.55rem;
            border: 1px solid rgba(255, 255, 255, 0.08);
        }
        
        .overlay-warning-title {
            font-size: 0.75rem;
            color: var(--text-secondary);
            margin-bottom: 0.2rem;
            text-transform: uppercase;
            letter-spacing: 0.05em;
        }
        
        .overlay-warning .warnings-list {
            max-height: 80px;
            overflow-y: auto;
            margin: 0;
            padding-left: 1rem;
        }
        
        .overlay-warning .warnings-list li {
            font-size: 0.72rem;
            color: var(--danger-color);
        }
        
        .proctoring-feed-card {
            background: #111;
            border-radius: 16px;
            overflow: hidden;
        }
        
        .proctoring-feed-card img,
        .proctoring-feed-card canvas {
            width: 100%;
            height: 240px;
            object-fit: cover;
            display: block;
        }
        
        .warnings-card {
            background: var(--bg-secondary);
            border-radius: 16px;
            padding: 1rem;
            border: 1px solid var(--border-color);
        }
        
        .warnings-card h4 {
            margin: 0 0 0.8rem 0;
            color: var(--text-secondary);
            font-weight: 600;
        }
        
        .audio-indicator-pill {
            display: none;
            align-items: center;
            gap: 0.4rem;
            font-size: 0.85rem;
            padding: 0.35rem 0.9rem;
            border-radius: 999px;
            background: rgba(102, 126, 234, 0.15);
            color: #4f63d4;
            font-weight: 600;
        }
        
        .audio-indicator-pill span {
            width: 8px;
            height: 8px;
            border-radius: 50%;
            background: #4f63d4;
            animation: blink 1.5s ease-in-out infinite;
        }
        
        #recording-indicator {
            display: none;
            margin-left: auto;
            padding: 0.35rem 0.8rem;
            border-radius: 999px;
            background: rgba(220, 53, 69, 0.15);
            color: #c82333;
            font-size: 0.8rem;
        }
        
        @media (max-width: 1400px) {
            .spoken-phase-layout {
                padding: 1.5rem;
                flex-direction: column;
            }
            .interview-main {
                min-width: 100%;
            }
            .proctoring-sidebar {
                flex: 1;
                width: 100%;
                position: relative;
                top: 0;
            }
            .proctoring-overlay {
                width: 220px;
                min-height: 210px;
                top: 15px;
                right: 15px;
            }
        }
        
        @media (max-width: 768px) {
            .proctoring-overlay {
                width: 180px;
                min-height: 190px;
                top: 12px;
                right: 12px;
                padding: 0.5rem;
            }
            .proctoring-overlay h3 {
                font-size: 0.7rem;
            }
            .proctoring-overlay .proctoring-feed-card img,
            .proctoring-overlay .proctoring-feed-card canvas {
                height: 120px;
            }
        }
        
        @media (max-width: 1200px) {
            .spoken-phase-layout {
                padding: 1rem;
            }
        }
        
        .instruction-item {
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .instruction-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(0,0,0,0.15) !important;
        }
        
        /* Responsive design for instructions - single column on mobile */
        @media (max-width: 768px) {
            #instructions-screen .instructions-container ul {
                grid-template-columns: 1fr !important;
            }
        }
        
        #start-technical-interview-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(118, 185, 0, 0.4) !important;
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.8; }
        }
        
        #coding-timer {
            transition: all 0.3s ease;
        }
        
        #camera-check-feed { 
            width: 100%; 
            height: auto; 
            border-radius: 15px; 
            background-color: #000; 
            aspect-ratio: 4 / 3;
            min-height: 200px;
            box-shadow: var(--shadow);
        }
        
        #verification-feed { 
            width: 100%; 
            max-width: 640px; 
            height: auto; 
            border-radius: 15px; 
            background-color: #000; 
            aspect-ratio: 4 / 3;
            box-shadow: var(--shadow);
        }
        
        .timer-display { 
            font-size: 3rem; 
            font-weight: bold; 
            text-align: center; 
            margin: 2rem 0;
            background: linear-gradient(135deg, var(--primary-color), var(--primary-dark));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            text-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .warnings-list { 
            list-style: none; 
            padding: 0; 
        }
        
        .warnings-list li { 
            background: linear-gradient(135deg, var(--danger-color), #c82333); 
            color: white; 
            padding: 0.75rem 1.5rem; 
            border-radius: 25px; 
            margin-bottom: 0.75rem; 
            text-align: center; 
            font-weight: 600; 
            font-size: 0.9rem;
            box-shadow: 0 4px 15px rgba(220, 53, 69, 0.3);
            animation: pulse 2s infinite;
        }
        
        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.05); }
            100% { transform: scale(1); }
        }
        
        @keyframes warningPop {
            0% { transform: scale(0.8); opacity: 0; }
            100% { transform: scale(1); opacity: 1; }
        }
        
        @keyframes warningFade {
            0% { transform: scale(1); opacity: 1; }
            100% { transform: scale(0.8); opacity: 0; }
        }
        
        .modal-overlay { 
            position: fixed; 
            top: 0; 
            left: 0; 
            width: 100%; 
            height: 100%; 
            background: rgba(0,0,0,0.8); 
            display: none; 
            justify-content: center; 
            align-items: center; 
            z-index: 1000;
            backdrop-filter: blur(5px);
        }
        
        .modal-content { 
            background: var(--bg-secondary); 
            padding: 3rem; 
            border-radius: 20px; 
            text-align: center; 
            max-width: 500px;
            box-shadow: var(--shadow-hover);
            border: 1px solid var(--border-color);
        }
        
        /* AI Interview Header Styles */
        .ai-interview-header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            border-radius: 20px;
            padding: 2rem;
            margin-bottom: 2rem;
            color: white;
            box-shadow: 0 8px 30px rgba(102, 126, 234, 0.3);
        }

        .ai-avatar-container {
            display: flex;
            align-items: center;
            gap: 1.5rem;
            margin-bottom: 1.5rem;
        }

        .ai-avatar {
            position: relative;
            width: 80px;
            height: 80px;
        }

        .ai-avatar-svg {
            width: 100%;
            height: 100%;
            filter: drop-shadow(0 4px 8px rgba(0,0,0,0.2));
        }

        /* SVG Gradient Definition */
        .ai-avatar-svg defs {
            display: block;
        }

        .ai-pulse-ring {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            width: 100%;
            height: 100%;
            border: 3px solid rgba(255,255,255,0.5);
            border-radius: 50%;
            animation: pulse-ring 2s ease-out infinite;
        }

        @keyframes pulse-ring {
            0% {
                transform: translate(-50%, -50%) scale(1);
                opacity: 1;
            }
            100% {
                transform: translate(-50%, -50%) scale(1.5);
                opacity: 0;
            }
        }

        .ai-status h2 {
            margin: 0;
            color: white !important;
            -webkit-text-fill-color: white !important;
        }

        .ai-status-text {
            color: rgba(255,255,255,0.9);
            font-size: 0.95rem;
            margin-top: 0.5rem;
        }

        .interview-progress {
            margin-top: 1rem;
        }

        .progress-bar-container {
            background: rgba(255,255,255,0.2);
            border-radius: 10px;
            height: 8px;
            overflow: hidden;
            margin-bottom: 0.5rem;
        }

        .progress-bar-fill {
            background: white;
            height: 100%;
            border-radius: 10px;
            transition: width 0.3s ease;
            width: 0%;
            box-shadow: 0 0 10px rgba(255,255,255,0.5);
        }

        .progress-text {
            color: rgba(255,255,255,0.9);
            font-size: 0.9rem;
            font-weight: 500;
        }

        /* AI Chat Container */
        .ai-chat-container {
            background: var(--bg-primary);
            border-radius: 20px;
            padding: 2rem;
            min-height: 500px;
            display: flex;
            flex-direction: column;
        }

        .chat-messages {
            flex: 1;
            overflow-y: auto;
            margin-bottom: 1.5rem;
            padding: 1rem;
            background: white;
            border-radius: 15px;
            max-height: 400px;
        }

        /* Message Bubbles */
        .ai-message-bubble {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 20px 20px 20px 5px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
            animation: slideInLeft 0.5s ease-out;
            position: relative;
        }

        .candidate-message-bubble {
            background: linear-gradient(135deg, #f8f9fa, #e9ecef);
            color: var(--text-primary);
            border-radius: 20px 20px 5px 20px;
            padding: 1.5rem;
            margin-bottom: 1.5rem;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            animation: slideInRight 0.5s ease-out;
            border: 2px solid var(--border-color);
        }

        @keyframes slideInLeft {
            from {
                opacity: 0;
                transform: translateX(-30px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        @keyframes slideInRight {
            from {
                opacity: 0;
                transform: translateX(30px);
            }
            to {
                opacity: 1;
                transform: translateX(0);
            }
        }

        @keyframes fadeOut {
            from {
                opacity: 1;
                transform: scale(1);
            }
            to {
                opacity: 0;
                transform: scale(0.95);
            }
        }

        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: scale(0.95) translateY(10px);
            }
            to {
                opacity: 1;
                transform: scale(1) translateY(0);
            }
        }

        @keyframes slideUpFade {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Enhanced Interactive Animations */
        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
                box-shadow: 0 8px 25px rgba(102, 126, 234, 0.4);
            }
            50% {
                transform: scale(1.05);
                box-shadow: 0 12px 35px rgba(102, 126, 234, 0.6);
            }
        }

        @keyframes ripple {
            0% {
                transform: translate(-50%, -50%) scale(1);
                opacity: 1;
            }
            100% {
                transform: translate(-50%, -50%) scale(1.5);
                opacity: 0;
            }
        }

        @keyframes blink {
            0%, 100% {
                opacity: 1;
            }
            50% {
                opacity: 0.3;
            }
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        /* Desktop Responsive Layout - Wide Screen Optimized */
        /* Note: Main layout styles are defined above, this section handles responsive breakpoints */

        /* Enhanced Button Styles */
        .btn-enhanced {
            transition: all 0.3s ease;
            cursor: pointer;
        }

        .btn-enhanced:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0,0,0,0.15) !important;
        }

        .btn-enhanced:active {
            transform: translateY(0);
        }

        /* Question Container Animation */
        .question-container-enhanced {
            animation: fadeInUp 0.6s ease-out;
        }

        /* Transcription Content Typing Effect */
        .transcription-content-enhanced {
            white-space: pre-wrap;
            word-wrap: break-word;
        }

        @keyframes typewriter {
            from {
                width: 0;
            }
            to {
                width: 100%;
            }
        }

        .question-container.fade-out {
            animation: fadeOut 0.3s ease-out forwards;
        }

        .question-container.fade-in {
            animation: fadeIn 0.5s ease-out forwards;
        }

        .question-text.typing {
            overflow: hidden;
            white-space: nowrap;
            border-right: 2px solid rgba(255,255,255,0.7);
            animation: typewriter 2s steps(40, end), blink-cursor 0.75s step-end infinite;
        }

        @keyframes blink-cursor {
            from, to {
                border-color: transparent;
            }
            50% {
                border-color: rgba(255,255,255,0.7);
            }
        }

        .ai-message-header, .candidate-message-header {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            margin-bottom: 1rem;
            font-size: 0.9rem;
            font-weight: 600;
        }

        .ai-avatar-small, .candidate-avatar-small {
            width: 32px;
            height: 32px;
            border-radius: 50%;
            background: rgba(255,255,255,0.2);
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.2rem;
        }

        .candidate-avatar-small {
            background: var(--primary-color);
            color: white;
        }

        .ai-label, .candidate-label {
            color: rgba(255,255,255,0.9);
        }

        .candidate-label {
            color: var(--text-secondary);
        }

        /* Typing Indicator */
        .typing-indicator {
            display: flex;
            gap: 4px;
            margin-left: auto;
        }

        .typing-indicator span {
            width: 8px;
            height: 8px;
            background: rgba(255,255,255,0.7);
            border-radius: 50%;
            animation: typing 1.4s infinite;
        }

        .typing-indicator span:nth-child(2) {
            animation-delay: 0.2s;
        }

        .typing-indicator span:nth-child(3) {
            animation-delay: 0.4s;
        }

        @keyframes typing {
            0%, 60%, 100% {
                transform: translateY(0);
                opacity: 0.7;
            }
            30% {
                transform: translateY(-10px);
                opacity: 1;
            }
        }

        .question-container {
            background: transparent;
            border: none;
            padding: 0;
            margin-bottom: 0;
        }
        
        .question-category {
            background: rgba(255,255,255,0.2);
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 20px;
            display: inline-block;
            font-weight: 600;
            font-size: 0.85rem;
            margin-bottom: 1rem;
            backdrop-filter: blur(10px);
        }
        
        .question-text {
            font-size: 1.2rem;
            line-height: 1.8;
            color: white;
            font-weight: 500;
            margin: 0;
        }

        .transcription-content {
            color: var(--text-primary);
            font-size: 1rem;
            line-height: 1.6;
            min-height: 50px;
        }
        
        .transcription-box {
            background: transparent;
            border: none;
            padding: 0;
            margin-top: 0;
            min-height: auto;
            font-style: normal;
        }

        /* Modern Timer Styles */
        .modern-timer {
            background: linear-gradient(135deg, #f8f9fa, #ffffff);
            border-radius: 15px;
            padding: 1.5rem;
            margin: 1rem 0;
            display: flex;
            align-items: center;
            gap: 1rem;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            border: 2px solid var(--border-color);
            animation: fadeInUp 0.5s ease-out;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .timer-icon {
            font-size: 2rem;
            width: 60px;
            height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
            background: linear-gradient(135deg, var(--primary-color), var(--primary-dark));
            border-radius: 15px;
            box-shadow: 0 4px 10px rgba(102, 126, 234, 0.3);
        }

        .thinking-timer .timer-icon {
            background: linear-gradient(135deg, #ffc107, #ff9800);
        }

        .answering-timer .timer-icon {
            background: linear-gradient(135deg, #28a745, #20c997);
            animation: pulse 2s ease-in-out infinite;
        }

        .review-timer .timer-icon {
            background: linear-gradient(135deg, #6c757d, #495057);
        }

        @keyframes pulse {
            0%, 100% {
                transform: scale(1);
            }
            50% {
                transform: scale(1.1);
            }
        }

        .timer-content {
            flex: 1;
        }

        .timer-label {
            font-size: 0.9rem;
            color: var(--text-secondary);
            margin-bottom: 0.25rem;
        }

        .timer-value {
            font-size: 1.8rem;
            font-weight: 700;
            color: var(--text-primary);
            font-family: 'Courier New', monospace;
        }

        /* Modern Button Styles */
        .modern-btn {
            display: flex;
            align-items: center;
            gap: 0.75rem;
            padding: 14px 28px;
            border-radius: 12px;
            font-weight: 600;
            transition: all 0.3s ease;
            position: relative;
            overflow: hidden;
        }

        .modern-btn::before {
            content: '';
            position: absolute;
            top: 50%;
            left: 50%;
            width: 0;
            height: 0;
            border-radius: 50%;
            background: rgba(255,255,255,0.3);
            transform: translate(-50%, -50%);
            transition: width 0.6s, height 0.6s;
        }

        .modern-btn:hover::before {
            width: 300px;
            height: 300px;
        }

        .btn-icon {
            font-size: 1.2rem;
            position: relative;
            z-index: 1;
        }

        .modern-btn span:not(.btn-icon) {
            position: relative;
            z-index: 1;
        }

        /* Enhanced Visualizer */
        .modern-visualizer {
            background: linear-gradient(135deg, #1e1e1e, #2d2d2d);
            border: 2px solid #444;
            box-shadow: 0 4px 20px rgba(0,0,0,0.3);
        }

        .visualizer-label {
            color: #fff;
            font-weight: 600;
            margin-bottom: 0.75rem;
            text-align: center;
            font-size: 0.9rem;
        }

        .interview-actions {
            display: flex;
            gap: 1rem;
            flex-wrap: wrap;
        }
        
        .transcription-box strong {
            color: var(--text-primary); /* Ensure strong text is consistent */
        }
        
        .transcription-box * {
            color: inherit; /* All child elements inherit the same color */
        }
        
        /* CRITICAL: Prevent browser from auto-styling URLs/links as blue */
        /* Browsers automatically detect URL patterns (like "www.example.com", "http://", "https://", 
           email addresses like "user@domain.com") and wrap them in <a> tags with blue color.
           This happens when innerHTML is set, causing new text to appear blue while old text stays black.
           Solution: Explicitly override link colors to match text color */
        .transcription-box a,
        .transcription-box a:link,
        .transcription-box a:visited,
        .transcription-box a:hover,
        .transcription-box a:active {
            color: var(--text-primary) !important; /* Force all links to use text color */
            text-decoration: none !important; /* Remove underline */
            cursor: text !important; /* Remove pointer cursor */
        }
        
        /* Audio Visualizer Styles - Only for Technical Interview */
        .audio-visualizer-container {
            width: 100%;
            max-width: 100%;
            height: 120px;
            margin: 1rem 0;
            background: var(--card-bg);
            border: 1px solid var(--border-color);
            border-radius: 12px;
            padding: 1rem;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }
        
        .audio-visualizer-canvas {
            width: 100%;
            height: 100%;
            display: block;
        }
        
        .coding-container {
            background: var(--bg-secondary);
            border-radius: 20px;
            padding: 2rem;
            box-shadow: var(--shadow);
        }
        
        .coding-problem {
            background: linear-gradient(135deg, #f8f9fa, #e9ecef);
            border-radius: 15px;
            padding: 2rem;
            margin-bottom: 2rem;
            border-left: 5px solid var(--warning-color);
        }
        
        .coding-actions {
            display: flex;
            gap: 1rem;
            margin: 1.5rem 0;
            flex-wrap: wrap;
        }
        
        .code-output {
            background: #1e1e1e;
            color: #d4d4d4;
            border-radius: 15px;
            padding: 1.5rem;
            margin-top: 1.5rem;
            font-family: 'Consolas', 'Monaco', monospace;
            border: 2px solid #333;
        }
        
        .status-indicator {
            display: inline-block;
            width: 12px;
            height: 12px;
            border-radius: 50%;
            margin-right: 8px;
            animation: blink 1.5s infinite;
        }
        
        .status-loading { background-color: var(--warning-color); }
        .status-success { background-color: var(--success-color); }
        .status-error { background-color: var(--danger-color); }
        
        @keyframes blink {
            0%, 50% { opacity: 1; }
            51%, 100% { opacity: 0.3; }
        }
        
        @media (max-width: 768px) {
            .spoken-phase-layout {
                grid-template-columns: 1fr;
            }
            
            .container {
                padding: 10px;
            }
            
            .card {
                padding: 1.5rem;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .timer-display {
                font-size: 2rem;
            }
        }
    </style>
</head>
<body>
<div class="container">
    {% if interview_started %}
        {{ spoken_questions_data|json_script:"spoken-questions-data" }}
        {{ coding_questions_data|json_script:"coding-questions-data" }}

        <!-- Phase 0: Setup Screens -->
        <div id="setup-phase" style="display: block;">
            <!-- Permission Check Screen - FIRST STEP -->
            <div id="permission-check-screen" class="card" style="text-align: center; max-width: 700px; margin: 0 auto; display: block;">
                <h1>üîê Permission & System Check</h1>
                <p style="color: var(--text-secondary); margin-bottom: 2.5rem; font-size: 1.1rem;">
                    We need to verify your camera, microphone, and network connection before starting the interview.
                </p>
                
                <div class="permission-checklist" style="margin: 2rem 0;">
                    <!-- Camera Permission -->
                    <div class="permission-item" id="camera-permission-item" style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 15px; padding: 1.5rem; margin-bottom: 1rem; display: flex; align-items: center; justify-content: space-between; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <span style="font-size: 2rem;">üì∑</span>
                            <div style="text-align: left;">
                                <h3 style="margin: 0; font-size: 1.2rem; color: var(--text-primary);">Camera Access</h3>
                                <p style="margin: 0.3rem 0 0 0; color: var(--text-secondary); font-size: 0.95rem;">Required for proctoring and identity verification</p>
                            </div>
                        </div>
                        <div id="camera-status" style="font-size: 1.5rem;">‚è≥</div>
                    </div>
                    
                    <!-- Microphone Permission -->
                    <div class="permission-item" id="mic-permission-item" style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 15px; padding: 1.5rem; margin-bottom: 1rem; display: flex; align-items: center; justify-content: space-between; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <span style="font-size: 2rem;">üé§</span>
                            <div style="text-align: left;">
                                <h3 style="margin: 0; font-size: 1.2rem; color: var(--text-primary);">Microphone Access</h3>
                                <p style="margin: 0.3rem 0 0 0; color: var(--text-secondary); font-size: 0.95rem;">Required for voice responses during interview</p>
                            </div>
                        </div>
                        <div id="mic-status" style="font-size: 1.5rem;">‚è≥</div>
                    </div>
                    
                    <!-- Network Connection -->
                    <div class="permission-item" id="network-permission-item" style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 15px; padding: 1.5rem; margin-bottom: 1rem; display: flex; align-items: center; justify-content: space-between; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <span style="font-size: 2rem;">üåê</span>
                            <div style="text-align: left;">
                                <h3 style="margin: 0; font-size: 1.2rem; color: var(--text-primary);">Network Connection</h3>
                                <p style="margin: 0.3rem 0 0 0; color: var(--text-secondary); font-size: 0.95rem;">Stable internet required for smooth interview</p>
                            </div>
                        </div>
                        <div id="network-status" style="font-size: 1.5rem;">‚è≥</div>
                    </div>
                </div>
                
                <div id="permission-error-message" style="display: none; background: #fff3cd; border: 2px solid #ffc107; border-radius: 10px; padding: 1rem; margin: 1.5rem 0; color: #856404;"></div>
                
                <button id="request-permissions-btn" class="btn submit-btn" style="padding: 16px 48px; font-size: 1.1rem; font-weight: 600; margin-top: 1rem;">
                    üîì Request Permissions
                </button>
                
                <button id="proceed-to-verification-btn" class="btn submit-btn" style="padding: 16px 48px; font-size: 1.1rem; font-weight: 600; margin-top: 1rem; display: none; background: linear-gradient(135deg, #28a745, #20c997);">
                    ‚úÖ All Set - Continue to Identity Verification
                </button>
            </div>
            
            <div id="camera-check-screen" class="card" style="display: none;">
                <h1>üé• Camera & System Check</h1>
                <p style="color: var(--text-secondary); margin-bottom: 2rem;">Please allow camera access. We are making sure everything is ready for your interview.</p>
                <div style="text-align: center;">
                    <img id="camera-check-feed" src="" alt="Camera feed" style="max-width: 100%; height: auto;">
                    <p id="camera-check-status" style="font-weight: 600; margin-top: 1rem; padding: 1rem; border-radius: 10px; background: var(--bg-primary);"></p>
                </div>
            </div>
            <div id="id-verification-screen" class="card" style="display: none; text-align: center;">
                <h1>üÜî ID Verification</h1>
                <p style="color: var(--text-secondary); margin-bottom: 2rem;">Please hold your ID card next to your face so both are clearly visible in the frame.</p>
                <div style="max-width: 640px; margin: 0 auto;">
                    <img id="verification-feed" style="width: 100%; max-width: 640px; height: auto; border-radius: 15px; background-color: #000; aspect-ratio: 4/3; margin-bottom: 1.5rem; display: block;" />
                    <canvas id="verification-canvas" style="display: none;"></canvas>
                    <button id="capture-id-btn" class="btn submit-btn" style="width: 100%; max-width: 300px;">üì∏ Capture & Verify ID</button>
                    <button id="start-coding-btn" class="btn done-btn" style="width: 100%; max-width: 300px; display: none;">üíª Start Coding Round</button>
                    <p id="id-verification-status" style="font-weight: 600; margin-top: 1rem; padding: 1rem; border-radius: 10px; background: var(--bg-primary);"></p>
                </div>
            </div>
            <div id="instructions-screen" class="card" style="display: none;">
                <div style="max-width: 1200px; margin: 0 auto; padding: 0 20px;">
                    <h1 style="text-align: center; color: var(--primary-color); margin-bottom: 0.3rem; font-size: 1.8rem;">üìã Interview Instructions</h1>
                    <p style="text-align: center; color: var(--text-secondary); margin-bottom: 1.5rem; font-size: 1rem;">Please read these instructions carefully before starting your interview</p>
                    
                    <div class="instructions-container" style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 20px; padding: 1.2rem 1.5rem; margin-bottom: 1.5rem; box-shadow: 0 4px 15px rgba(0,0,0,0.1);">
                        <ul style="list-style: none; display: grid; grid-template-columns: repeat(2, 1fr); gap: 0.6rem; margin: 0; padding: 0;">
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">‚èπÔ∏è</span>Wait for the question to finish before answering.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üëÅÔ∏è</span>Look at the camera while answering.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">ü§´</span>Keep movements minimal and stay centered.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üñ•Ô∏è</span>Do not switch tabs or minimize the window.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üó£Ô∏è</span>Speak clearly and at a normal volume.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üìù</span>Do not read from notes or other screens.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üëÇ</span>When 'Listening' appears, answer or respond to the question at that time.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üôÇ</span>Keep a calm, neutral expression.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üì∑</span>Keep your full face visible at all times.</li>
                            <li class="instruction-item" style="background: white; border-radius: 10px; padding: 0.7rem 0.9rem; box-shadow: 0 2px 8px rgba(0,0,0,0.06); font-size: 0.95rem;"><span style="margin-right: 8px;">üìµ</span>Do not use phones or other devices.</li>
                        </ul>
                    </div>
                    
                    <div style="text-align: center; margin-top: 1.5rem;">
                        <button id="start-technical-interview-btn" class="btn submit-btn" style="padding: 14px 40px; font-size: 1.1rem; font-weight: 600; border-radius: 12px; box-shadow: 0 4px 15px rgba(118, 185, 0, 0.3); transition: all 0.3s;">
                            üé§ Start Technical Interview
                        </button>
                    </div>
                </div>
            </div>
        </div>

        <!-- Phase 1: Spoken Interview -->
        <div id="spoken-interview-phase" class="spoken-phase-layout" data-session-id="{{ interview_session_id }}" style="display: none;">
            <!-- Proctoring Camera Overlay - Top Right -->
            <div class="proctoring-overlay" id="proctoring-overlay-tech">
                <h3>Proctoring Monitor</h3>
                <div style="font-size: 0.7rem; color: var(--text-secondary); text-align: center; margin-bottom: 0.5rem;">
                    Session: <span id="proctoring-session-id-tech">{{ interview_session_id|default:session_key|slice:":8" }}</span>
                </div>
                <div class="proctoring-feed-card" style="position: relative;">
                    <img id="proctoring-feed" alt="Proctoring Camera Feed" />
                    <canvas id="proctoring-feed-canvas" style="display:none;"></canvas>
                    <!-- LIVE Indicator -->
                    <div class="live-indicator" style="position: absolute; top: 8px; right: 8px; background: rgba(220, 53, 69, 0.9); color: white; padding: 4px 8px; border-radius: 4px; font-size: 0.65rem; font-weight: 700; letter-spacing: 0.05em;">
                        LIVE
                    </div>
                    <!-- Timestamp Overlay -->
                    <div class="timestamp-overlay" id="timestamp-overlay-tech" style="position: absolute; bottom: 8px; left: 8px; background: rgba(0, 0, 0, 0.7); color: white; padding: 4px 8px; border-radius: 4px; font-size: 0.7rem; font-family: monospace; font-weight: 600;">
                        00:00:00
                    </div>
                </div>
                <div class="overlay-warning">
                    <div class="overlay-warning-title">‚ö†Ô∏è Active Warnings</div>
                    <ul id="warnings-list" class="warnings-list"></ul>
                </div>
            </div>
            
            <div class="interview-main card">
                <div class="question-panel-header" style="margin-bottom: 1.5rem;">
                    <div>
                        <h2 style="margin: 0; color: var(--primary-color);">AI Technical Interview</h2>
                    </div>
                    <span id="progress-text" class="question-progress-text">Question 1 of 1</span>
                </div>

                <div class="progress-section-enhanced" style="margin-bottom: 1.5rem;">
                    <div class="progress-bar-container-enhanced">
                        <div class="progress-fill-enhanced" id="interview-progress-bar"></div>
                    </div>
                    <div id="ai-status-indicator" style="color: var(--text-secondary); font-size: 0.95rem;">Ready to begin...</div>
                </div>

                <div id="question-container" class="question-container-enhanced card" style="padding: 1.5rem; background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%); border: 1px solid #e9ecef;">
                    <p id="question-text" style="margin: 0; font-size: 1.25rem; line-height: 1.8; color: var(--text-primary); font-weight: 500;"></p>
                    <div id="audio-playing-indicator" class="audio-indicator-pill" style="margin-top: 1rem;">
                        <span></span>
                        Playing question audio
                    </div>
                </div>

                <div style="display: flex; flex-direction: column; gap: 1rem; margin-top: 1.5rem;">
                    <div id="thinking-timer" class="timer-display-enhanced thinking-timer" style="display:none;">
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <span style="font-size: 1.5rem;">üí≠</span>
                            <div>
                                <div style="font-size: 0.85rem; color: #856404; font-weight: 600; margin-bottom: 0.2rem;">Thinking Time</div>
                                <div id="thinking-timer-value" style="font-size: 1.4rem; font-weight: 700; color: #856404;"></div>
                            </div>
                        </div>
                    </div>
                    <div id="answering-timer" class="timer-display-enhanced answering-timer" style="display:none;">
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <span style="font-size: 1.5rem;">üé§</span>
                            <div>
                                <div style="font-size: 0.85rem; color: #0c5460; font-weight: 600; margin-bottom: 0.2rem;">Listening</div>
                                <div id="answering-timer-value" style="font-size: 1.4rem; font-weight: 700; color: #0c5460;"></div>
                            </div>
                        </div>
                    </div>
                    <div id="review-timer-display" class="timer-display-enhanced review-timer" style="display:none;">
                        <div style="display: flex; align-items: center; gap: 1rem;">
                            <span style="font-size: 1.5rem;">‚è±Ô∏è</span>
                            <div>
                                <div style="font-size: 0.85rem; color: #155724; font-weight: 600; margin-bottom: 0.2rem;">Review</div>
                                <div id="review-timer-value" style="font-size: 1.4rem; font-weight: 700; color: #155724;"></div>
                            </div>
                        </div>
                    </div>
                </div>

                <button id="done-btn" class="btn done-btn" style="display:none; margin-top: 1.5rem; width: 100%;">‚úÖ I'm Done Answering</button>

                <div id="transcription-box" class="transcription-box-enhanced card" style="margin-top: 2rem; position: relative;">
                    <div id="transcription-content" class="transcription-content-enhanced" style="color: var(--text-primary); font-size: 1.05rem; line-height: 1.8; min-height: 100px;"></div>
                </div>

                <audio id="question-audio-element" style="display: none !important; visibility: hidden; width: 0; height: 0;"></audio>
            </div>
        </div>

        <!-- Phase 2: Coding Challenge -->
        <div id="coding-interview-phase" class="spoken-phase-layout" style="display: none;">
            <!-- Proctoring Camera Overlay - Top Right -->
            <div class="proctoring-overlay" id="proctoring-overlay-coding">
                <h3>Proctoring Monitor</h3>
                <div style="font-size: 0.7rem; color: var(--text-secondary); text-align: center; margin-bottom: 0.5rem;">
                    Session: <span id="proctoring-session-id-coding">{{ interview_session_id|default:session_key|slice:":8" }}</span>
                </div>
                <div class="proctoring-feed-card" style="position: relative;">
                    <img id="proctoring-feed-2" alt="Proctoring Camera Feed" />
                    <canvas id="proctoring-feed-canvas-2" style="display:none;"></canvas>
                    <!-- LIVE Indicator -->
                    <div class="live-indicator" style="position: absolute; top: 8px; right: 8px; background: rgba(220, 53, 69, 0.9); color: white; padding: 4px 8px; border-radius: 4px; font-size: 0.65rem; font-weight: 700; letter-spacing: 0.05em;">
                        LIVE
                    </div>
                    <!-- Timestamp Overlay -->
                    <div class="timestamp-overlay" id="timestamp-overlay-coding" style="position: absolute; bottom: 8px; left: 8px; background: rgba(0, 0, 0, 0.7); color: white; padding: 4px 8px; border-radius: 4px; font-size: 0.7rem; font-family: monospace; font-weight: 600;">
                        00:00:00
                    </div>
                </div>
                <div class="overlay-warning">
                    <div class="overlay-warning-title">‚ö†Ô∏è Active Warnings</div>
                    <ul id="warnings-list-2" class="warnings-list"></ul>
                </div>
            </div>
            
            <div class="interview-main card">
                <div class="question-panel-header" style="margin-bottom: 1.5rem;">
                    <div>
                        <h2 style="margin: 0; color: var(--primary-color);">üíª Coding Challenge</h2>
                    </div>
                    <div id="coding-timer" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 12px 24px; border-radius: 12px; font-size: 1.2rem; font-weight: 600; box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3); min-width: 140px; text-align: center;">
                        ‚è±Ô∏è 20:00
                    </div>
                </div>
                
                <div id="coding-problem-container" class="coding-problem card" style="padding: 1.5rem; background: linear-gradient(135deg, #ffffff 0%, #f8f9fa 100%); border: 1px solid #e9ecef; margin-bottom: 1.5rem;">
                    <h2 id="coding-question-title" style="margin-top:0; margin-bottom: 0.5rem; color: var(--primary-color); font-size: 1.3rem;"></h2>
                    <h3 id="coding-language-display" style="margin-top:0; margin-bottom: 1rem; color: var(--text-secondary); font-size: 1rem;"></h3>
                    <p id="coding-problem-text" style="font-size: 1.1rem; line-height: 1.7; color: var(--text-primary); margin: 0;"></p>
                </div>
                
                <div id="monaco-editor-container" style="width: 100%; height: 400px; border: 2px solid var(--border-color); border-radius: 15px; overflow: hidden; margin-bottom: 1.5rem;"></div>
                
                <div class="coding-actions" style="display: flex; gap: 1rem; margin-bottom: 1.5rem;">
                    <button id="run-code-btn" class="btn" style="flex: 1;">‚ñ∂Ô∏è Run Code</button>
                    <button id="submit-code-btn" class="btn submit-btn" style="flex: 1;">üöÄ Submit & End Interview</button>
                </div>
                
                <div id="code-output-container" class="code-output card" style="background: #2d2d2d; color: #f8f9fa; padding: 1.5rem; border-radius: 15px;">
                    <h4 style="color: #fff; margin-bottom: 1rem; font-size: 1.1rem;">üì§ Output:</h4>
                    <pre id="code-output-pre" style="white-space: pre-wrap; word-wrap: break-word; margin: 0; font-family: 'Courier New', monospace; font-size: 0.9rem; line-height: 1.6;"></pre>
                </div>
            </div>
        </div>
    {% endif %}
</div>

<div id="termination-modal" class="modal-overlay">
    <div class="modal-content">
        <h2>‚ö†Ô∏è Absence Detected</h2>
        <p style="color: var(--text-secondary); margin-bottom: 2rem;">The interview will be terminated if you do not return within the time limit.</p>
        <div id="termination-timer" class="timer-display"></div>
        <button id="cancel-termination-btn" class="btn cancel-btn">‚úÖ I'm Back - Continue Interview</button>
    </div>
</div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.33.0/min/vs/loader.min.js"></script>
    <script src="{% static 'interview_video_recorder_complete.js' %}"></script>
    <script src="{% static 'interview_audio_recorder.js' %}"></script>

<script>
    const SESSION_KEY = "{{ session_key|default:''|escapejs }}";
    const MOVE_TO_NEXT_AUDIO_URL = "{{ move_to_next_audio_url }}";
    const INTERVIEW_SESSION_ID = "{{ interview_session_id }}";
    const CANDIDATE_NAME = "{{ candidate_name|default:'Candidate'|escapejs }}";
    const JOB_DESCRIPTION = `{{ job_description|default:''|escapejs }}`;

    const spokenQuestions = JSON.parse(document.getElementById('spoken-questions-data').textContent || '[]');
    const codingQuestions = JSON.parse(document.getElementById('coding-questions-data').textContent || '[]');
    
    console.log('üîç DEBUG: Loaded coding questions from server:', codingQuestions);
    console.log('üîç DEBUG: Number of coding questions:', codingQuestions.length);
    if (codingQuestions.length > 0) {
        console.log('üîç DEBUG: First coding question:', codingQuestions[0]);
    }
    
    let currentSpokenQuestionIndex = -1;
    let currentCodingQuestionIndex = -1;
    let monacoEditor;
    let interviewEnded = false;
    let codingTimerInterval = null;
    let codingTimeRemaining = 20 * 60; // 20 minutes in seconds (1200 seconds)
    let questionStartTime; 
    let verificationStream;
    let thinkingTimer, answeringTimer, reviewInterval, proctoringInterval, noAnswerTimeout;
    const THINKING_TIME = 20, ANSWERING_TIME = 60, REVIEW_TIME = 10, TERMINATION_TIME = 60;
    let hasStartedSpeaking = false;
    
    // Audio Recorder - Records microphone + TTS audio (video handled by backend)
    let audioRecorder = null;
    let uploadedAudioPath = null; // Store uploaded audio path for merging
    
    // Listen for audio upload events
    window.addEventListener('audioUploaded', function(event) {
        if (event.detail && event.detail.audioPath) {
            uploadedAudioPath = event.detail.audioPath;
            window.uploadedAudioPath = event.detail.audioPath;
            console.log('üì¢ Received audioUploaded event, path:', event.detail.audioPath);
        }
    });
    
    // Initialize audio recorder when page loads and script is ready
    function initializeAudioRecorder() {
        if (typeof InterviewAudioRecorder === 'undefined') {
            console.warn('‚ö†Ô∏è InterviewAudioRecorder class not loaded yet, retrying...');
            setTimeout(initializeAudioRecorder, 100);
            return;
        }
        
        if (SESSION_KEY) {
            try {
                audioRecorder = new InterviewAudioRecorder(SESSION_KEY);
                console.log('‚úÖ Audio recorder initialized for session:', SESSION_KEY);
                console.log('üìä Audio recorder object:', audioRecorder);
                
                // Expose audio recorder to window for debugging
                window.audioRecorder = audioRecorder;
                console.log('üí° Audio recorder available at window.audioRecorder for debugging');
            } catch (error) {
                console.error('‚ùå Failed to initialize audio recorder:', error);
                console.error('‚ùå Error stack:', error.stack);
            }
        } else {
            console.warn('‚ö†Ô∏è SESSION_KEY not available, audio recorder not initialized');
        }
    }
    
    // Initialize when DOM is ready
    if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', initializeAudioRecorder);
    } else {
        // DOM already loaded
        initializeAudioRecorder();
    }
    
    // Debug function to manually test audio recording
    window.testAudioRecording = async function() {
        console.log('üß™ Testing audio recording...');
        if (!audioRecorder) {
            console.error('‚ùå Audio recorder not initialized');
            if (typeof InterviewAudioRecorder !== 'undefined' && SESSION_KEY) {
                console.log('üîÑ Attempting to initialize...');
                audioRecorder = new InterviewAudioRecorder(SESSION_KEY);
                window.audioRecorder = audioRecorder;
            } else {
                console.error('‚ùå Cannot initialize: InterviewAudioRecorder class or SESSION_KEY not available');
                return false;
            }
        }
        
        if (audioRecorder.isRecording) {
            console.log('‚ö†Ô∏è Already recording, stopping first...');
            await audioRecorder.stopRecording();
            await new Promise(resolve => setTimeout(resolve, 1000));
        }
        
        console.log('üéôÔ∏è Starting test audio recording...');
        const success = await audioRecorder.startRecording();
        if (success) {
            console.log('‚úÖ Test audio recording started successfully');
            console.log('üìä Recording state:', {
                isRecording: audioRecorder.isRecording,
                hasMicrophoneStream: !!audioRecorder.microphoneStream
            });
        } else {
            console.error('‚ùå Test audio recording failed to start');
        }
        return success;
    };
    let isTerminationWarningVisible = false, terminationWarningInterval = null;
    let mediaRecorder, audioChunks = [], currentAudio = new Audio(), moveNextAudio = new Audio(MOVE_TO_NEXT_AUDIO_URL), audioContext, micSource, scriptProcessor;
    // Ensure audio element is hidden and has no controls
    currentAudio.controls = false;
    currentAudio.style.display = 'none';
    currentAudio.style.visibility = 'hidden';
    let silenceDetector = { counter: 0, threshold: 39 };
    
    // Audio Visualizer variables - Only for Technical Interview
    let audioAnalyser = null;
    let visualizerAnimationId = null;
    let visualizerCanvas = null;
    let visualizerCtx = null;
    let visualizerDataArray = null;
    // Deepgram WebSocket variables
    // SIMPLIFIED STATE MANAGEMENT - Never clears text during recording
    let deepgramWS = null;
    
    // ‚úÖ SIMPLIFIED STATE: Single source of truth
    let accumulatedTranscript = '';  // All text received (never cleared during recording)
    let lastUpdateTime = Date.now();
    const SILENCE_THRESHOLD = 5000;  // 5 seconds of actual silence
    
    // Legacy variable names (kept for compatibility, will be synced)
    let deepgramPartialText = ''; // Synced with: accumulatedTranscript
    let accumulatedFinalText = ''; // Synced with: accumulatedTranscript
    let lastKnownTranscript = ''; // Synced with: accumulatedTranscript
    let completeTranscript = ''; // Synced with: accumulatedTranscript
    let currentUtterance = ''; // Current interim (for display only)
    let lastReceivedText = ''; // Synced with: accumulatedTranscript
    
    const DEEPGRAM_API_KEY = '6690abf90d1c62c6b70ed632900b2c093bc06d79'; // Hardcoded API key
    
    // ‚úÖ MONITOR SILENCE INDEPENDENTLY (don't rely on Deepgram)
    let silenceCheckInterval = null;
    let isRecordingActive = false; // Track if recording is active
    let hasEverReceivedText = false; // Track if we've ever received any transcript
    let answeringPhaseStartTime = null; // Track when answering phase started
    const MAX_ANSWERING_TIME = 10000; // 10 seconds maximum total time
    const SILENCE_FOR_AUTO_SUBMIT = 5000; // 5 seconds of silence to auto-submit
    const MIN_RECORDING_TIME = 8000; // Minimum 2 seconds before auto-submit can trigger
    
    // Function to start silence monitoring
    function startSilenceMonitoring() {
        if (silenceCheckInterval) return;
        
        // Record when answering phase started
        answeringPhaseStartTime = Date.now();
        
        silenceCheckInterval = setInterval(() => {
            if (!isRecordingActive) {
                clearInterval(silenceCheckInterval);
                silenceCheckInterval = null;
                answeringPhaseStartTime = null;
                return;
            }
            
            const now = Date.now();
            const silenceDuration = now - lastUpdateTime;
            const totalRecordingTime = now - answeringPhaseStartTime;
            
            // Only show "No voice" if:
            // 1. No text ever received AND
            // 2. 5+ seconds of silence
            if (!hasEverReceivedText && silenceDuration > SILENCE_THRESHOLD) {
                const transcriptionContent = document.getElementById('transcription-content');
                if (transcriptionContent) {
                    transcriptionContent.innerHTML = `<span class='status-indicator status-waiting'></span><strong style='color: var(--text-primary);'>No speech detected. Please speak clearly into your microphone.</strong>`;
                }
            }
            
            // ‚úÖ AUTO-SUBMIT LOGIC:
            // 1. Must have received at least some text (hasEverReceivedText = true)
            // 2. Must have been recording for at least MIN_RECORDING_TIME (2 seconds)
            // 3. Must have 5 seconds of silence after last transcript
            // 4. Maximum 10 seconds total recording time
            if (hasEverReceivedText && 
                totalRecordingTime >= MIN_RECORDING_TIME && 
                silenceDuration >= SILENCE_FOR_AUTO_SUBMIT) {
                console.log('‚úÖ Auto-submitting: 5 seconds of silence detected after transcript');
                console.log(`   Total recording time: ${totalRecordingTime}ms`);
                console.log(`   Silence duration: ${silenceDuration}ms`);
                stopSilenceMonitoring();
                moveToReviewPhase();
                return;
            }
            
            // ‚úÖ MAX TIME REACHED: Auto-submit after 10 seconds total
            if (totalRecordingTime >= MAX_ANSWERING_TIME) {
                console.log('‚úÖ Auto-submitting: Maximum 10 seconds reached');
                console.log(`   Total recording time: ${totalRecordingTime}ms`);
                stopSilenceMonitoring();
                moveToReviewPhase();
                return;
            }
        }, 1000); // Check every 1 second
    }
    
    // Function to stop silence monitoring
    function stopSilenceMonitoring() {
        if (silenceCheckInterval) {
            clearInterval(silenceCheckInterval);
            silenceCheckInterval = null;
        }
        answeringPhaseStartTime = null; // Reset start time
    }
    
    // NEW FUNCTION: Reset transcript ONLY when starting a brand new question
    // Call this when starting a new question session, NOT during recording
    function resetTranscript() {
        console.log('üîÑ Resetting transcript for new question');
        accumulatedTranscript = '';
        deepgramPartialText = '';
        accumulatedFinalText = '';
        lastKnownTranscript = '';
        completeTranscript = '';
        currentUtterance = '';
        lastReceivedText = '';
        hasEverReceivedText = false;
        lastUpdateTime = Date.now();
        // DO NOT clear isRecordingActive here - that's managed separately
    }
    
    // NEW FUNCTION: Get full transcript for submission
    // ‚úÖ Always return accumulated (never empty unless truly no speech)
    function getFullTranscript() {
        return accumulatedTranscript.trim() || '';
    }
    
    // NEW FUNCTION: Sync legacy variables with new state
    function syncTranscriptVariables() {
        // Sync all legacy variables with accumulatedTranscript
        deepgramPartialText = accumulatedTranscript;
        accumulatedFinalText = accumulatedTranscript;
        lastKnownTranscript = accumulatedTranscript;
        completeTranscript = accumulatedTranscript;
        lastReceivedText = accumulatedTranscript;
    }
    // When true, keep proctoring ON but do not auto-start spoken Q&A (external chatbot in use)
    let PROCTOR_ONLY = false;

    // Network status monitoring
    window.addEventListener('online', () => {
        if (document.getElementById('network-status')) {
            checkNetworkConnection();
        }
    });
    
    window.addEventListener('offline', () => {
        const statusEl = document.getElementById('network-status');
        if (statusEl) {
            statusEl.textContent = '‚ùå';
            statusEl.style.color = '#dc3545';
            updatePermissionStatus();
        }
    });

    // Tab switch detection - report to backend when tab visibility changes
    document.addEventListener('visibilitychange', function() {
        if (!SESSION_KEY || interviewEnded) return;
        const isHidden = document.hidden || document.webkitHidden || document.mozHidden || false;
        console.log(`üìë Tab visibility changed: ${isHidden ? 'hidden' : 'visible'}`);
        
        // Report to backend
        fetch("{% url 'report_tab_switch' %}", {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                session_key: SESSION_KEY,
                status: isHidden ? 'hidden' : 'visible'
            })
        }).catch(err => console.error('Error reporting tab switch:', err));
    });

    document.addEventListener('DOMContentLoaded', () => {
        console.log('‚úÖ DOM Content Loaded - Initializing permission check...');
        
        // Optional: allow jumping straight to coding via URL parameter
        try {
            const urlParams = new URLSearchParams(window.location.search);
            const phase = urlParams.get('phase');
            if (phase === 'coding') {
                document.getElementById('setup-phase').style.display = 'none';
                startCodingPhase();
                return;
            }
        } catch (e) {
            console.error('Error checking URL params:', e);
        }
        
        // Ensure setup phase is visible
        const setupPhase = document.getElementById('setup-phase');
        const permissionScreen = document.getElementById('permission-check-screen');
        
        if (setupPhase) {
            setupPhase.style.display = 'block';
            console.log('‚úÖ Setup phase is visible');
        } else {
            console.error('‚ùå Setup phase element not found!');
        }
        
        if (permissionScreen) {
            permissionScreen.style.display = 'block';
            console.log('‚úÖ Permission check screen is visible');
        } else {
            console.error('‚ùå Permission check screen element not found!');
        }
        
        // Start with permission check screen
        if (permissionScreen) {
            console.log('üîç Starting permission check...');
            checkInitialPermissions();
        } else {
            console.error('‚ùå Cannot start permission check - screen not found');
        }
        
        // Permission check button handlers
        const requestBtn = document.getElementById('request-permissions-btn');
        const proceedBtn = document.getElementById('proceed-to-verification-btn');
        
        if (requestBtn) {
            requestBtn.addEventListener('click', (e) => {
                console.log('üîì Request Permissions button clicked');
                e.preventDefault();
                requestAllPermissions();
            });
            console.log('‚úÖ Request permissions button handler attached');
        } else {
            console.error('‚ùå Request permissions button not found!');
        }
        
        if (proceedBtn) {
            proceedBtn.addEventListener('click', (e) => {
                console.log('‚úÖ Proceed to verification button clicked');
                e.preventDefault();
                proceedToVerification();
            });
            console.log('‚úÖ Proceed to verification button handler attached');
        } else {
            console.warn('‚ö†Ô∏è Proceed to verification button not found (will appear when permissions are granted)');
        }
        
        // Other button handlers
        document.getElementById('capture-id-btn')?.addEventListener('click', runIdVerification);
        document.getElementById('start-technical-interview-btn')?.addEventListener('click', startTechnicalInterview);
        document.getElementById('start-coding-btn')?.addEventListener('click', () => {
            try { document.getElementById('setup-phase').style.display = 'none'; } catch (e) {}
            startCodingPhase();
        });
        document.getElementById('start-coding-btn-proctor')?.addEventListener('click', () => {
            startCodingPhase();
        });
        document.getElementById('finish-chatbot-btn')?.addEventListener('click', () => {
            // Show coding round after user confirms Q&A completion
            showCodingRound();
        });
        document.getElementById('cancel-termination-btn')?.addEventListener('click', hideTerminationWarning);
    });
    
    // Permission checking functions
    async function checkInitialPermissions() {
        console.log('üîç Checking initial permissions...');
        
        // Ensure permission check screen is visible
        const permissionScreen = document.getElementById('permission-check-screen');
        const setupPhase = document.getElementById('setup-phase');
        if (permissionScreen && setupPhase) {
            setupPhase.style.display = 'block';
            permissionScreen.style.display = 'block';
            console.log('‚úÖ Permission check screen is visible');
        } else {
            console.error('‚ùå Permission check screen or setup-phase not found!');
            return;
        }
        
        // Check network first (doesn't require user interaction)
        try {
        await checkNetworkConnection();
        } catch (e) {
            console.error('Error checking network:', e);
        }
        
        // Check camera and mic permissions (may show prompts)
        try {
        await checkCameraPermission();
        } catch (e) {
            console.error('Error checking camera:', e);
        }
        
        try {
        await checkMicrophonePermission();
        } catch (e) {
            console.error('Error checking microphone:', e);
        }
        
        // If all are granted, show proceed button
        updatePermissionStatus();
    }
    
    async function checkCameraPermission() {
        const statusEl = document.getElementById('camera-status');
        if (!statusEl) {
            console.error('‚ùå Camera status element not found!');
            return false;
        }
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            statusEl.textContent = '‚úÖ';
            statusEl.style.color = '#28a745';
            // Release stream immediately - we'll request again later
            stream.getTracks().forEach(track => track.stop());
            return true;
        } catch (err) {
            console.error('Camera permission error:', err);
            if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                statusEl.textContent = '‚ùå';
                statusEl.style.color = '#dc3545';
            } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
                statusEl.textContent = '‚ö†Ô∏è';
                statusEl.style.color = '#ffc107';
            } else {
                statusEl.textContent = '‚ùå';
                statusEl.style.color = '#dc3545';
            }
            return false;
        }
    }
    
    async function checkMicrophonePermission() {
        const statusEl = document.getElementById('mic-status');
        if (!statusEl) {
            console.error('‚ùå Microphone status element not found!');
            return false;
        }
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            statusEl.textContent = '‚úÖ';
            statusEl.style.color = '#28a745';
            // Release stream immediately - we'll request again later
            stream.getTracks().forEach(track => track.stop());
            return true;
        } catch (err) {
            console.error('Microphone permission error:', err);
            if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                statusEl.textContent = '‚ùå';
                statusEl.style.color = '#dc3545';
            } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
                statusEl.textContent = '‚ö†Ô∏è';
                statusEl.style.color = '#ffc107';
            } else {
                statusEl.textContent = '‚ùå';
                statusEl.style.color = '#dc3545';
            }
            return false;
        }
    }
    
    async function checkNetworkConnection() {
        const statusEl = document.getElementById('network-status');
        if (!statusEl) {
            console.error('‚ùå Network status element not found!');
            return false;
        }
        
        // Check if online
        if (!navigator.onLine) {
            statusEl.textContent = '‚ùå';
            statusEl.style.color = '#dc3545';
            return false;
        }
        
        // Try to fetch a small resource to verify connectivity
        try {
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 3000); // 3 second timeout
            
            const response = await fetch(window.location.origin + '/static/', {
                method: 'HEAD',
                signal: controller.signal,
                cache: 'no-cache'
            }).catch(() => {
                // If fetch fails, try a simpler check
                return { ok: navigator.onLine };
            });
            
            clearTimeout(timeoutId);
            
            if (navigator.onLine) {
                statusEl.textContent = '‚úÖ';
                statusEl.style.color = '#28a745';
                return true;
            } else {
                statusEl.textContent = '‚ùå';
                statusEl.style.color = '#dc3545';
                return false;
            }
        } catch (err) {
            // If fetch fails but we're online, assume connection is okay
            if (navigator.onLine) {
                statusEl.textContent = '‚úÖ';
                statusEl.style.color = '#28a745';
                return true;
            } else {
                statusEl.textContent = '‚ùå';
                statusEl.style.color = '#dc3545';
                return false;
            }
        }
    }
    
    async function requestAllPermissions() {
        const errorEl = document.getElementById('permission-error-message');
        errorEl.style.display = 'none';
        
        const requestBtn = document.getElementById('request-permissions-btn');
        requestBtn.disabled = true;
        requestBtn.textContent = '‚è≥ Requesting...';
        
        try {
            // Request camera and microphone together
            const stream = await navigator.mediaDevices.getUserMedia({
                video: true,
                audio: true
            });
            
            // Check permissions again
            await checkCameraPermission();
            await checkMicrophonePermission();
            await checkNetworkConnection();
            
            // Release stream
            stream.getTracks().forEach(track => track.stop());
            
            // Update UI
            updatePermissionStatus();
            requestBtn.disabled = false;
            requestBtn.textContent = 'üîì Request Permissions';
            
        } catch (err) {
            console.error('Permission request error:', err);
            requestBtn.disabled = false;
            requestBtn.textContent = 'üîì Request Permissions';
            
            let errorMsg = 'Failed to get permissions. ';
            if (err.name === 'NotAllowedError' || err.name === 'PermissionDeniedError') {
                errorMsg += 'Please allow camera and microphone access in your browser settings and try again.';
            } else if (err.name === 'NotFoundError' || err.name === 'DevicesNotFoundError') {
                errorMsg += 'No camera or microphone found. Please connect a camera and microphone.';
            } else if (err.name === 'NotReadableError') {
                errorMsg += 'Camera or microphone is being used by another application. Please close other applications and try again.';
            } else {
                errorMsg += err.message || 'Unknown error occurred.';
            }
            
            errorEl.textContent = errorMsg;
            errorEl.style.display = 'block';
            
            // Still check individual permissions to show status
            await checkCameraPermission();
            await checkMicrophonePermission();
            updatePermissionStatus();
        }
    }
    
    function updatePermissionStatus() {
        const cameraStatusEl = document.getElementById('camera-status');
        const micStatusEl = document.getElementById('mic-status');
        const networkStatusEl = document.getElementById('network-status');
        
        if (!cameraStatusEl || !micStatusEl || !networkStatusEl) {
            console.error('‚ùå Permission status elements not found!', {
                camera: !!cameraStatusEl,
                mic: !!micStatusEl,
                network: !!networkStatusEl
            });
            return;
        }
        
        const cameraStatus = cameraStatusEl.textContent.trim();
        const micStatus = micStatusEl.textContent.trim();
        const networkStatus = networkStatusEl.textContent.trim();
        
        console.log('üìä Permission status:', {
            camera: cameraStatus,
            mic: micStatus,
            network: networkStatus
        });
        
        const allGranted = cameraStatus === '‚úÖ' && micStatus === '‚úÖ' && networkStatus === '‚úÖ';
        
        const proceedBtn = document.getElementById('proceed-to-verification-btn');
        const requestBtn = document.getElementById('request-permissions-btn');
        
        if (allGranted) {
            if (proceedBtn) {
            proceedBtn.style.display = 'inline-block';
                proceedBtn.style.animation = 'fadeInUp 0.5s ease-out';
            }
            if (requestBtn) {
                requestBtn.style.display = 'none';
            }
            console.log('‚úÖ All permissions granted - showing proceed button');
        } else {
            if (proceedBtn) proceedBtn.style.display = 'none';
            if (requestBtn) {
                requestBtn.style.display = 'inline-block';
                requestBtn.style.animation = 'fadeInUp 0.5s ease-out';
            }
            console.log('‚ö†Ô∏è Some permissions not granted - showing request button');
        }
    }
    
    function proceedToVerification() {
        console.log('‚úÖ Proceeding to verification...');
        
        // Hide permission check screen and show camera check screen
        const permissionScreen = document.getElementById('permission-check-screen');
        const cameraCheckScreen = document.getElementById('camera-check-screen');
        
        if (permissionScreen) {
            permissionScreen.style.display = 'none';
            console.log('‚úÖ Permission check screen hidden');
        } else {
            console.error('‚ùå Permission check screen not found!');
        }
        
        if (cameraCheckScreen) {
            cameraCheckScreen.style.display = 'block';
            console.log('‚úÖ Camera check screen shown');
        } else {
            console.error('‚ùå Camera check screen not found!');
            return;
        }
        
        // Run camera check which will then proceed to ID verification
        runCameraCheck();
    }
    
    // Release media resources when page is about to unload
    window.addEventListener('beforeunload', function() {
        releaseMediaResources();
    });

    async function runCameraCheck() {
        const statusEl = document.getElementById('camera-check-status');
        const feedEl = document.getElementById('camera-check-feed');
        const cameraCheckScreen = document.getElementById('camera-check-screen');
        
        // Only run if camera check screen is visible
        if (!cameraCheckScreen || cameraCheckScreen.style.display === 'none') {
            return;
        }
        
        statusEl.innerText = "Initializing camera...";
        try {
            const response = await fetch(`{% url 'check_camera' %}?session_key=${SESSION_KEY}`);
            if (!response.ok) { const errData = await response.json(); throw new Error(errData.message || "Server error."); }
            const data = await response.json();
            
            // Check if browser camera should be used (e.g., on cloud servers like Render)
            const useBrowserCamera = data.browser_camera === true;
            window.USE_BROWSER_CAMERA = useBrowserCamera;
            
            if (useBrowserCamera) {
                console.log('üåê Using browser camera (no server hardware camera available)');
                statusEl.innerText = "Browser camera will be used";
                // Skip backend video feed and proceed directly to verification
                setTimeout(() => {
                    document.getElementById('camera-check-screen').style.display = 'none';
                    document.getElementById('id-verification-screen').style.display = 'block';
                    startVerificationCamera();
                }, 500);
            } else {
            statusEl.innerText = "Camera detected. Waiting for video stream...";
            feedEl.src = `{% url 'video_feed' %}?session_key=${SESSION_KEY}&t=${new Date().getTime()}`;
            console.log('üì∫ Video feed URL set:', feedEl.src);
            
            let feedLoaded = false;
            
            feedEl.onload = async () => {
                console.log('‚úÖ Video feed loaded successfully');
                if (feedLoaded) return; // Prevent multiple calls
                feedLoaded = true;
                
                statusEl.innerText = "Camera check successful!";
                // DON'T release camera here - it needs to stay alive for the interview!
                setTimeout(() => {
                    document.getElementById('camera-check-screen').style.display = 'none';
                    document.getElementById('id-verification-screen').style.display = 'block';
                    startVerificationCamera();
                }, 1000);
            };
            
            feedEl.onerror = (e) => { 
                console.error('‚ùå Video feed error:', e);
                throw new Error("Could not display video feed."); 
            };
            
            // Fallback timeout in case onload doesn't fire
            setTimeout(async () => {
                if (!feedLoaded) {
                    console.log('‚è∞ Video feed timeout - proceeding anyway');
                    feedLoaded = true;
                    statusEl.innerText = "Camera check successful!";
                    // DON'T release camera here - it needs to stay alive for the interview!
                    setTimeout(() => {
                        document.getElementById('camera-check-screen').style.display = 'none';
                        document.getElementById('id-verification-screen').style.display = 'block';
                        startVerificationCamera();
                    }, 1000);
                }
            }, 3000); // 3 second timeout
            }
        } catch (err) {
            statusEl.innerText = `Error: ${err.message}`;
            statusEl.style.color = "red";
        }
    }
    
    function startVerificationCamera() {
        const imgEl = document.getElementById('verification-feed');
        const statusEl = document.getElementById('id-verification-status');
        
        if (!imgEl) {
            console.error('‚ùå Verification feed element not found');
            return;
        }
        
        // Check if browser camera should be used
        const useBrowserCamera = window.USE_BROWSER_CAMERA === true;
        
        if (useBrowserCamera) {
            console.log('üåê Starting verification camera (using browser camera)...');
            statusEl.innerText = "Requesting camera access...";
            statusEl.style.color = "";
            
            // Use browser's getUserMedia API
            navigator.mediaDevices.getUserMedia({ 
                video: { 
                    width: { ideal: 640 },
                    height: { ideal: 480 },
                    facingMode: 'user'
                },
                audio: false 
            })
            .then(stream => {
                console.log('‚úÖ Browser camera access granted');
                window._verificationStream = stream;
                
                // Create a hidden video element to capture frames
                let videoEl = document.getElementById('verification-video-hidden');
                if (!videoEl) {
                    videoEl = document.createElement('video');
                    videoEl.id = 'verification-video-hidden';
                    videoEl.style.display = 'none';
                    videoEl.autoplay = true;
                    videoEl.playsInline = true;
                    document.body.appendChild(videoEl);
                }
                
                videoEl.srcObject = stream;
                videoEl.onloadedmetadata = () => {
                    videoEl.play();
                    
                    // Create canvas to capture frames
                    let canvasEl = document.getElementById('verification-canvas-hidden');
                    if (!canvasEl) {
                        canvasEl = document.createElement('canvas');
                        canvasEl.id = 'verification-canvas-hidden';
                        canvasEl.style.display = 'none';
                        document.body.appendChild(canvasEl);
                    }
                    
                    canvasEl.width = videoEl.videoWidth || 640;
                    canvasEl.height = videoEl.videoHeight || 480;
                    const ctx = canvasEl.getContext('2d');
                    
                    // Update image element with frames from video
                    const updateFrame = () => {
                        if (interviewEnded) {
                            if (window._verificationFrameInterval) {
                                clearInterval(window._verificationFrameInterval);
                            }
                            if (stream) {
                                stream.getTracks().forEach(track => track.stop());
                            }
                            return;
                        }
                        
                        try {
                            ctx.drawImage(videoEl, 0, 0, canvasEl.width, canvasEl.height);
                            imgEl.src = canvasEl.toDataURL('image/jpeg', 0.8);
                            
                            if (statusEl.innerText === "Requesting camera access..." || statusEl.innerText === "Initializing camera...") {
                                statusEl.innerText = "Camera ready. Hold your ID card next to your face.";
                                statusEl.style.color = "green";
                            }
                        } catch (e) {
                            console.warn('‚ö†Ô∏è Failed to capture frame:', e);
                        }
                    };
                    
                    // Update at ~15fps for smooth preview
                    window._verificationFrameInterval = setInterval(updateFrame, 67);
                    updateFrame(); // Start immediately
                    
                    statusEl.innerText = "Camera ready. Hold your ID card next to your face.";
                    statusEl.style.color = "green";
                };
            })
            .catch(err => {
                console.error('‚ùå Browser camera access denied:', err);
                statusEl.innerText = `Error: ${err.name === 'NotAllowedError' ? 'Camera access denied. Please allow camera access.' : 'Failed to access camera.'}`;
                statusEl.style.color = "red";
            });
        } else {
        console.log('üé• Starting verification camera (using backend feed)...');
        statusEl.innerText = "Initializing camera...";
        statusEl.style.color = "";
        
        // Use backend video feed instead of getUserMedia (avoids camera conflict)
        const frameUrl = `{% url 'video_frame' %}?session_key=${SESSION_KEY}`;
        let frameUpdateInterval = null;
        
        const updateFrame = () => {
            if (interviewEnded) {
                if (frameUpdateInterval) clearInterval(frameUpdateInterval);
                return;
            }
            
            const url = `${frameUrl}&t=${Date.now()}&cache=${Math.random()}`;
            imgEl.onload = () => {
                console.log('‚úÖ Verification frame loaded');
                if (statusEl.innerText === "Initializing camera...") {
                    statusEl.innerText = "Camera ready. Hold your ID card next to your face.";
                    statusEl.style.color = "green";
                }
            };
            imgEl.onerror = () => {
                console.warn('‚ö†Ô∏è Failed to load verification frame');
            };
            imgEl.src = url;
        };
        
        // Start polling for frames every 500ms (~2fps - sufficient for verification, reduces load)
        frameUpdateInterval = setInterval(updateFrame, 500);
        updateFrame(); // Start immediately
        
        console.log('‚úÖ Verification camera feed started (backend video)');
        statusEl.innerText = "Camera ready. Hold your ID card next to your face.";
        statusEl.style.color = "green";
        
        // Store interval so we can clear it later
        window._verificationFrameInterval = frameUpdateInterval;
        }
    }

    function startTechnicalInterview() {
        console.log('üé§ Starting technical interview...');
        
        // Hide instructions screen
        document.getElementById('instructions-screen').style.display = 'none';
        document.getElementById('setup-phase').style.display = 'none';
        
        // Keep proctoring enabled AND keep PROCTOR_ONLY = true to disable old interview system
        PROCTOR_ONLY = true;
        console.log('%c‚úÖ Setting PROCTOR_ONLY = true to disable old interview system', 'background: #222; color: #bada55; font-size: 14px;');
        
        // ACTIVATE YOLOv8n detection when technical interview starts
        // This also starts video recording and returns the exact start timestamp
        fetch("{% url 'activate_proctoring_camera' %}", {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ session_key: SESSION_KEY })
        })
        .then(response => response.json())
        .then(data => {
            if (data.status === 'success') {
                console.log('‚úÖ YOLOv8n detection activated for technical interview:', data);
                
                // Get video start timestamp for audio synchronization
                const videoStartTimestamp = data.video_start_timestamp;
                if (videoStartTimestamp) {
                    console.log('üïê Video recording started at timestamp:', videoStartTimestamp);
                    // Store timestamp for audio synchronization
                    window.videoStartTimestamp = videoStartTimestamp;
                    
                    // CRITICAL: Start audio recording IMMEDIATELY with the EXACT same timestamp
                    // The video timestamp is recorded when start_video_recording() is called (not when first frame is written)
                    // This ensures both video and audio use the SAME timestamp for perfect synchronization
                    const currentTime = Date.now() / 1000; // Current time in seconds
                    const timeDiff = Math.abs(videoStartTimestamp - currentTime);
                    
                    console.log(`üïê Video timestamp: ${videoStartTimestamp}, Current time: ${currentTime}`);
                    console.log(`‚è±Ô∏è Time difference: ${(timeDiff * 1000).toFixed(2)}ms`);
                    
                    // Start audio IMMEDIATELY with video timestamp - this ensures perfect synchronization
                    // The audio recorder will use the video timestamp as the authoritative start time
                    console.log(`üéôÔ∏è Starting audio recording IMMEDIATELY with video timestamp for perfect synchronization...`);
                    startAudioRecording(0, videoStartTimestamp); // Pass video timestamp for exact sync
                   } else {
                       // Fallback: start audio recording with small delay
                       console.warn('‚ö†Ô∏è No video timestamp received, starting audio with default delay');
                       startAudioRecording();
                   }
            } else {
                console.warn('‚ö†Ô∏è Failed to activate YOLOv8n:', data.message);
                // CRITICAL: Don't start audio without video timestamp - wait for video to start
                console.warn('‚ö†Ô∏è Not starting audio recording - waiting for video timestamp');
            }
        })
        .catch(error => {
            console.error('‚ùå Error activating YOLOv8n:', error);
            // CRITICAL: Don't start audio without video timestamp - wait for video to start
            console.warn('‚ö†Ô∏è Not starting audio recording - waiting for video timestamp');
        });
        
        const spokenPhase = document.getElementById('spoken-interview-phase');
        if (spokenPhase) {
            spokenPhase.style.display = 'grid';
            // Ensure SESSION_KEY is accessible to iframe
            window.SESSION_KEY = SESSION_KEY;
            console.log('%c‚úÖ Set window.SESSION_KEY =', 'background: #222; color: #bada55; font-size: 14px;', window.SESSION_KEY);
            // Start the integrated chatbot instead of old interview system
            startIntegratedChatbot();
            // Show the "finished Q&A" control; coding button stays hidden until clicked
            const finishBtn = document.getElementById('finish-chatbot-btn');
            if (finishBtn) finishBtn.style.display = 'inline-block';
        }
        
        // Start proctoring monitors with getUserMedia cameras
        startProctoringMonitors();
    }

    async function runIdVerification() {
        const statusEl = document.getElementById('id-verification-status');
        const imgEl = document.getElementById('verification-feed');
        const canvasEl = document.getElementById('verification-canvas');
        
        const useBrowserCamera = window.USE_BROWSER_CAMERA === true;
        let imageDataUrl;
        
        if (useBrowserCamera) {
            // Capture directly from video element for better quality
            const videoEl = document.getElementById('verification-video-hidden');
            if (!videoEl || !videoEl.videoWidth || !videoEl.videoHeight) {
                statusEl.innerText = "Error: Camera not ready. Please wait for camera to initialize.";
                statusEl.style.color = "red";
                console.error('‚ùå Video element not ready');
                return;
            }
            
            statusEl.innerText = "Processing, please hold still...";
            statusEl.style.color = "";
            
            // Use the canvas element or create one to capture the image
            const canvas = canvasEl || document.createElement('canvas');
            canvas.width = videoEl.videoWidth;
            canvas.height = videoEl.videoHeight;
            const ctx = canvas.getContext('2d');
            
            // Draw the current frame from the video element
            ctx.drawImage(videoEl, 0, 0, canvas.width, canvas.height);
            imageDataUrl = canvas.toDataURL('image/jpeg', 0.9);
        } else {
            // Check if image is loaded (backend feed)
        if (!imgEl || !imgEl.complete || !imgEl.naturalWidth) {
            statusEl.innerText = "Error: Camera not ready. Please wait for camera to initialize.";
            statusEl.style.color = "red";
            console.error('‚ùå Image not loaded - complete:', imgEl?.complete, 'naturalWidth:', imgEl?.naturalWidth);
            return;
        }
        
        if (imgEl.naturalWidth === 0 || imgEl.naturalHeight === 0) {
            statusEl.innerText = "Error: Image dimensions invalid. Please wait a moment and try again.";
            statusEl.style.color = "red";
            console.error('‚ùå Invalid image dimensions');
            return;
        }
        
        statusEl.innerText = "Processing, please hold still...";
        statusEl.style.color = "";
        
        // Use the canvas element or create one to capture the image
        const canvas = canvasEl || document.createElement('canvas');
        canvas.width = imgEl.naturalWidth;
        canvas.height = imgEl.naturalHeight;
        const ctx = canvas.getContext('2d');
        
        // Draw the current frame from the backend feed
        ctx.drawImage(imgEl, 0, 0, canvas.width, canvas.height);
            imageDataUrl = canvas.toDataURL('image/jpeg', 0.9);
        }
        const formData = new FormData();
        formData.append('session_id', INTERVIEW_SESSION_ID);
        formData.append('image_data', imageDataUrl);
            
        try {
            const response = await fetch("{% url 'verify_id' %}", { method: 'POST', body: formData });
            const result = await response.json();
            if (result.status === 'success') {
                statusEl.innerText = "Verification successful!";
                statusEl.style.color = 'green';
                
                // Clean up verification feed interval
                if (window._verificationFrameInterval) {
                    clearInterval(window._verificationFrameInterval);
                    window._verificationFrameInterval = null;
                }
                
                // Clean up browser camera stream if used
                if (window._verificationStream) {
                    window._verificationStream.getTracks().forEach(track => track.stop());
                    window._verificationStream = null;
                }
                
                // Show instructions screen instead of going directly to interview
                setTimeout(() => {
                    document.getElementById('id-verification-screen').style.display = 'none';
                    document.getElementById('instructions-screen').style.display = 'block';
                }, 1500);
            } else {
                throw new Error(result.message || "Verification failed.");
            }
        } catch (err) {
            statusEl.innerText = `Error: ${err.message}`;
            statusEl.style.color = 'red';
        }
    }

    // Listen for messages from chatbot iframe
    window.addEventListener('message', function(event) {
        // Log all messages for debugging
        if (event.data && event.data.type) {
            console.log(`üì® Received message from iframe: ${event.data.type}`, event.data);
        }
        
        if (event.data && event.data.type === 'qa_completed') {
            // Q&A is complete, show coding round
            showCodingRound();
        }
        if (event.data && event.data.type === 'start_coding_round') {
            // Start coding round from chatbot
            console.log('üíª Received start_coding_round message from chatbot');
            startCodingRound();
        }
        if (event.data && event.data.type === 'interview_started') {
            // Interview started in iframe - backend already started video via activate_yolo_proctoring
            // DO NOT start audio or video here; audio must start only when we receive video_start_timestamp
            console.log('üé• Interview started in iframe (backend video already running). Audio will start when video_start_timestamp is received.');
        }
        if (event.data && event.data.type === 'coding_started') {
            // Coding phase started - backend video continues automatically
            // Do not touch audio here to keep synchronization intact
            console.log('üíª Coding phase started (backend video continues). Audio recording state unchanged.');
        }
    });
    
           // Function to start audio recording (microphone + TTS)
           // Backend handles video recording, frontend only records audio
           window.startAudioRecording = function startAudioRecording(delay = 0, videoStartTimestamp = null) {
               console.log('üé¨ startAudioRecording() called');
               console.log('üìä Current state:', {
                   audioRecorder: !!audioRecorder,
                   InterviewAudioRecorder: typeof InterviewAudioRecorder,
                   SESSION_KEY: SESSION_KEY,
                   videoStartTimestamp: videoStartTimestamp
               });
               
               if (!audioRecorder) {
                   console.warn('‚ö†Ô∏è Audio recorder not initialized, attempting to initialize now...');
                   if (typeof InterviewAudioRecorder !== 'undefined' && SESSION_KEY) {
                       try {
                           audioRecorder = new InterviewAudioRecorder(SESSION_KEY);
                           window.audioRecorder = audioRecorder;
                           console.log('‚úÖ Audio recorder initialized successfully');
                       } catch (error) {
                           console.error('‚ùå Error initializing audio recorder:', error);
                           return;
                       }
                   } else {
                       console.error('‚ùå Cannot initialize audio recorder:', {
                           InterviewAudioRecorder: typeof InterviewAudioRecorder,
                           SESSION_KEY: SESSION_KEY
                       });
                       return;
                   }
               }
               
               if (audioRecorder.isRecording) {
                   console.log('‚úÖ Audio recording already in progress');
                   return;
               }
               
               // CRITICAL: If videoStartTimestamp is provided, start audio IMMEDIATELY (no delay)
               // This ensures audio and video start at the exact same time for perfect synchronization
               if (videoStartTimestamp) {
                   console.log(`üïê Video start timestamp provided: ${videoStartTimestamp}`);
                   console.log('üéôÔ∏è Starting audio recording IMMEDIATELY (no delay) for exact synchronization...');
                   // Start immediately - no setTimeout delay
                   audioRecorder.startRecording(videoStartTimestamp).then(success => {
                       if (success) {
                           console.log('‚úÖ Audio recording started successfully with exact video synchronization');
                       } else {
                           console.warn('‚ö†Ô∏è Audio recording failed to start');
                       }
                   }).catch(err => {
                       console.error('‚ùå Error starting audio recording:', err);
                   });
               } else {
                   // DO NOT start audio without a confirmed videoStartTimestamp
                   // This avoids unsynchronized audio that cannot be perfectly merged
                   console.warn('‚ö†Ô∏è videoStartTimestamp not provided - NOT starting audio recording to avoid desync');
               }
           }
           
           // Keep old function name for compatibility but DO NOT start audio here.
           // Audio must start ONLY when we have video_start_timestamp from activate_yolo_proctoring
           window.startVideoRecording = function startVideoRecording(delay = 1000) {
               console.log('üé¨ startVideoRecording() called - video handled entirely by backend.');
               console.log('üé¨ Audio start is controlled by activate_yolo_proctoring using video_start_timestamp only. No action taken here.');
           }

    // Function to show coding round after Q&A completion
    function showCodingRound() {
        console.log('üéâ Technical Q&A Complete! Starting coding round...');
        // Auto-start coding round instead of showing button
        startCodingRound();
    }

    // Function to start coding round
    function startCodingRound() {
        console.log('üöÄ Starting coding round...');
        
        // Hide setup phase and chatbot container
        const setupPhase = document.getElementById('setup-phase');
        const spokenPhase = document.getElementById('spoken-interview-phase');
        const questionContainer = document.getElementById('question-container');
        
        if (setupPhase) setupPhase.style.display = 'none';
        if (spokenPhase) spokenPhase.style.display = 'none';
        if (questionContainer) questionContainer.style.display = 'none';
        
        // Ensure video recording is active for coding phase
        startVideoRecording();
        
        // Start the coding phase
        startCodingPhase();
    }

    // === Integrated Chatbot ===
    async function startIntegratedChatbot() {
        console.log('%cüöÄ STARTING INTEGRATED CHATBOT', 'background: #222; color: #bada55; font-size: 16px;');
        const container = document.getElementById('question-container');
        console.log('%cüìç Container found:', 'color: blue; font-weight: bold;', !!container);
        if (container) {
            console.log('%cüìç Creating chatbot iframe with standalone template...', 'color: blue; font-weight: bold;');
            // Use standalone template instead of blob URL
            container.innerHTML = `<div id="integrated-chatbot" style="padding: 1rem; border-radius: 12px; background: var(--bg-primary);">
                <div id="cb-status" class="status info" style="margin-bottom: 10px;">Loading technical Q&A...</div>
                <iframe id="cb-frame" src="{% url 'chatbot_standalone' %}?session_key=${SESSION_KEY}" title="AI Interview Chatbot" style="width:100%; height:720px; border: 0; border-radius: 10px; background: #fff;"></iframe>
            </div>`;
            console.log('%c‚úÖ Chatbot iframe created with standalone template!', 'color: green; font-weight: bold;');
            
            // Start video recording when chatbot iframe is created (fallback if postMessage fails)
            console.log('üé• Starting video recording (fallback when chatbot loads)...');
            // CRITICAL: Don't start audio here - wait for video timestamp from activate_yolo_proctoring
            console.log('‚ö†Ô∏è Waiting for video timestamp before starting audio recording...');
        } else {
            console.error('%c‚ùå Container not found!', 'color: red; font-weight: bold;');
        }
    }

    // OLD BLOB IFRAME CODE REMOVED - NOW USING STANDALONE TEMPLATE AT /chatbot/

    function runInterview() {
        const container = document.getElementById('question-container');
        container.innerHTML = `<p style="text-align:center; font-size: 1.2em;">Initializing proctoring camera... Please wait.</p>`;
        startProctoringMonitors();
    }

    // Video recording functions removed

    function startFirstSpokenQuestion() {
        console.log("Starting first spoken question...");
        console.log("Spoken questions count:", spokenQuestions.length);
        console.log("Coding questions count:", codingQuestions.length);
        
        // CRITICAL: Only start audio if video timestamp is available
        // Audio should have already started when video started (via activate_yolo_proctoring)
        if (window.videoStartTimestamp && audioRecorder && !audioRecorder.isRecording) {
            console.log("üéôÔ∏è Starting audio recording with video timestamp...");
            startAudioRecording(0, window.videoStartTimestamp);
        } else if (audioRecorder && audioRecorder.isRecording) {
            console.log("‚úÖ Audio recording already active");
        } else {
            console.warn("‚ö†Ô∏è Video timestamp not available - audio will start when video timestamp is received");
        }
        
        if (spokenQuestions.length > 0) {
            console.log("Starting spoken questions phase");
            // Set to first question (index 0) without incrementing
            currentSpokenQuestionIndex = 0;
            displayCurrentQuestion();
        } else {
            console.log("No spoken questions, starting coding phase");
            startCodingPhase();
        }
    }

    function displayCurrentQuestion() {
        console.log("displayCurrentQuestion called, currentSpokenQuestionIndex:", currentSpokenQuestionIndex);
        if (interviewEnded) return;
        
        // CRITICAL: Reset transcript when starting a NEW question
        // This is the ONLY place where transcript should be cleared
        resetTranscript();
        
        hasStartedSpeaking = false;
        silenceDetector.counter = 0;

        const thinkingTimer = document.getElementById('thinking-timer');
        const answeringTimer = document.getElementById('answering-timer');
        const reviewTimer = document.getElementById('review-timer-display');
        const doneBtn = document.getElementById('done-btn');
        
        if (thinkingTimer) thinkingTimer.style.display = 'none';
        if (answeringTimer) answeringTimer.style.display = 'none';
        if (doneBtn) doneBtn.style.display = 'none';
        if (reviewTimer) reviewTimer.style.display = 'none';

        console.log("Current question index:", currentSpokenQuestionIndex);
        console.log("Total spoken questions:", spokenQuestions.length);
        
        if (currentSpokenQuestionIndex >= spokenQuestions.length) {
            console.log("All spoken questions completed, starting coding phase");
            startCodingPhase();
            return;
        }

        const q = spokenQuestions[currentSpokenQuestionIndex];
        console.log("Loading question:", q);
        
        // Update progress
        const totalQuestions = spokenQuestions.length;
        const currentQuestion = currentSpokenQuestionIndex + 1;
        const progressBar = document.getElementById('interview-progress-bar');
        const progressText = document.getElementById('progress-text');
        if (progressBar) {
            progressBar.style.width = `${(currentQuestion / totalQuestions) * 100}%`;
        }
        if (progressText) {
            progressText.textContent = `Question ${currentQuestion} of ${totalQuestions}`;
        }
        
        // Display question in simple format
        const questionContainer = document.getElementById('question-container');
        const questionTextEl = document.getElementById('question-text');
        
        if (questionContainer && questionTextEl) {
            questionContainer.style.display = 'block';
            questionTextEl.textContent = q.text;
        }
        
        // Update status indicator
        const statusIndicator = document.getElementById('ai-status-indicator');
        if (statusIndicator) {
            statusIndicator.textContent = 'Asking question...';
        }
        
        // Update transcription box
        const transcriptionContent = document.getElementById('transcription-content');
        if (transcriptionContent) {
            transcriptionContent.innerHTML = "<span style='color: var(--text-secondary); font-style: italic;'>Listening for the question...</span>";
        }
        
        if(q.audio_url && q.audio_url.trim()){
            // Use Google Cloud TTS audio if available
            // Show audio playing indicator
            const audioIndicator = document.getElementById('audio-playing-indicator');
            if (audioIndicator) {
                audioIndicator.style.display = 'block';
            }
            
            currentAudio.src = q.audio_url;
            currentAudio.controls = false;
            currentAudio.style.display = 'none';
            currentAudio.style.visibility = 'hidden';
            console.log("Playing audio from:", q.audio_url);
            currentAudio.play().catch(e => console.error("Error playing question audio:", e));
            currentAudio.onended = () => {
                console.log("Audio ended, starting thinking phase");
                // Hide audio playing indicator
                if (audioIndicator) {
                    audioIndicator.style.display = 'none';
                }
                questionStartTime = new Date(); 
                startThinkingPhase();
            };
            currentAudio.onerror = () => {
                // Hide indicator on error
                if (audioIndicator) {
                    audioIndicator.style.display = 'none';
                }
            };
        }else{
            // Use browser's built-in TTS as fallback when Google Cloud TTS is not available
            console.log("No audio URL, using browser TTS fallback");
            if('speechSynthesis' in window && q.text){
                const utterance = new SpeechSynthesisUtterance(q.text);
                utterance.rate = 0.9;
                utterance.pitch = 1.0;
                utterance.volume = 1.0;
                utterance.onend = () => {
                    console.log("Browser TTS ended, starting thinking phase");
                    questionStartTime = new Date(); 
                    startThinkingPhase();
                };
                utterance.onerror = (e) => {
                    console.error("Browser TTS error:", e);
                    questionStartTime = new Date(); 
                    startThinkingPhase();
                };
                speechSynthesis.speak(utterance);
            }else{
                // No TTS available, go directly to thinking phase
                console.log("No TTS available, starting thinking phase immediately");
                questionStartTime = new Date(); 
                startThinkingPhase();
            }
        }
    }

    function nextSpokenQuestion() {
        // Increment index and display the next question
        console.log("nextSpokenQuestion called, currentSpokenQuestionIndex before increment:", currentSpokenQuestionIndex);
        if (interviewEnded) return;
        stopRecordingAndProcessing();
        clearTimeout(noAnswerTimeout);
        clearInterval(thinkingTimer); clearInterval(answeringTimer); clearInterval(reviewInterval);
        
        currentSpokenQuestionIndex++;
        console.log("New currentSpokenQuestionIndex after increment:", currentSpokenQuestionIndex);
        displayCurrentQuestion();
    }

    function startThinkingPhase() {
        if (interviewEnded) return;
        startRecordingAndMonitoring();
        let timeLeft = THINKING_TIME;
        const timer = document.getElementById('thinking-timer');
        const timerValue = document.getElementById('thinking-timer-value');
        if (timer) {
            timer.style.display = 'flex';
            timer.style.animation = 'fadeInUp 0.5s ease-out';
        }
        if (timerValue) {
            timerValue.textContent = `${formatTime(timeLeft)}`;
        }
        
        // Status update removed - using simple UI
        
        thinkingTimer = setInterval(() => {
            timeLeft--;
            if (timerValue) {
                timerValue.textContent = `${formatTime(timeLeft)}`;
            }
            if (timeLeft < 0) { 
                clearInterval(thinkingTimer);
                if (timer) timer.style.display = 'none';
                if (!hasStartedSpeaking) {
                    startAnswerGracePeriod();
                }
            }
        }, 1000);
    }

    function startAnswerGracePeriod() {
        if (interviewEnded || hasStartedSpeaking) return;
        document.getElementById('thinking-timer').style.display = 'none';
        const transcriptionContent = document.getElementById('transcription-content');
        if (transcriptionContent) {
            transcriptionContent.innerHTML = "<span style='color: var(--text-secondary);'>Please begin speaking now... You have 15 seconds.</span>";
        }
        noAnswerTimeout = setTimeout(forceNextQuestion, 15000);
    }

    function forceNextQuestion() {
        if (interviewEnded || hasStartedSpeaking) return;
        clearTimeout(noAnswerTimeout);
        stopRecordingAndProcessing();
        moveNextAudio.play();
        moveNextAudio.onended = () => nextSpokenQuestion();
    }

    function startAnsweringPhase() {
        if (hasStartedSpeaking || interviewEnded) return;
        clearTimeout(noAnswerTimeout);
        hasStartedSpeaking = true;
        clearInterval(thinkingTimer);
        document.getElementById('thinking-timer').style.display = 'none';
        
        // Initialize transcript timeout tracking for "No speech detected" message
        lastUpdateTime = Date.now();
        
        // CRITICAL: Don't overwrite transcription box if there's already a transcript
        // This prevents erasing early transcripts when user starts speaking continuously
        // Only show "Recording..." if there's no transcript yet
        const transcriptionContent = document.getElementById('transcription-content');
        const hasExistingTranscript = accumulatedTranscript.trim().length > 0;
        if (!hasExistingTranscript && transcriptionContent) {
            transcriptionContent.innerHTML = "<span class='status-indicator status-loading'></span><i style='color: var(--text-secondary);'>Recording...</i>";
        } else {
            // Update with existing transcript instead of overwriting
            updateDisplay(accumulatedTranscript);
        }
        
        // Start silence monitoring (separate from Deepgram)
        startSilenceMonitoring();
        
        // Show and start audio visualizer (only for technical interview)
        startAudioVisualizer();
        
        // Show timer with 10 seconds maximum (matching MAX_ANSWERING_TIME)
        const timer = document.getElementById('answering-timer');
        const timerValue = document.getElementById('answering-timer-value');
        if (timer) {
            timer.style.display = 'flex';
            timer.style.animation = 'fadeInUp 0.5s ease-out';
        }
        const doneBtn = document.getElementById('done-btn');
        if (doneBtn) doneBtn.style.display = 'flex';
        
        // Update status
        // Status update removed - using simple UI
        
        answeringTimer = setInterval(() => {
            if (!answeringPhaseStartTime) {
                answeringPhaseStartTime = Date.now(); // Fallback if not set
            }
            const elapsed = Date.now() - answeringPhaseStartTime;
            const remaining = Math.max(0, Math.floor((MAX_ANSWERING_TIME - elapsed) / 1000));
            if (timerValue) {
                timerValue.textContent = `${formatTime(remaining)}`;
            }
            
            // Auto-submit if max time reached
            if (elapsed >= MAX_ANSWERING_TIME) {
                clearInterval(answeringTimer);
                moveToReviewPhase();
            }
        }, 100); // Update every 100ms for smoother countdown
    }
    
    function startAudioVisualizer() {
        // Only show visualizer during technical interview answering phase
        if (!audioAnalyser || !audioContext) {
            console.log('‚ö†Ô∏è Audio analyser not available for visualizer');
            return;
        }
        
        // Get canvas element
        visualizerCanvas = document.getElementById('audio-visualizer');
        if (!visualizerCanvas) {
            console.log('‚ö†Ô∏è Audio visualizer canvas not found');
            return;
        }
        
        visualizerCtx = visualizerCanvas.getContext('2d');
        visualizerCanvas.width = visualizerCanvas.offsetWidth;
        visualizerCanvas.height = visualizerCanvas.offsetHeight;
        
        // Create data array for frequency analysis
        const bufferLength = audioAnalyser.frequencyBinCount;
        visualizerDataArray = new Uint8Array(bufferLength);
        
        // Show visualizer container
        const visualizerContainer = document.getElementById('audio-visualizer-container');
        if (visualizerContainer) {
            visualizerContainer.style.display = 'block';
        }
        
        // Start animation loop
        drawAudioVisualizer();
    }
    
    function drawAudioVisualizer() {
        if (!visualizerCanvas || !visualizerCtx || !audioAnalyser || !visualizerDataArray) {
            return;
        }
        
        // Only continue if visualizer is visible (answering phase)
        const visualizerContainer = document.getElementById('audio-visualizer-container');
        if (!visualizerContainer || visualizerContainer.style.display === 'none') {
            return;
        }
        
        // Get frequency data
        audioAnalyser.getByteFrequencyData(visualizerDataArray);
        
        // Clear canvas
        visualizerCtx.fillStyle = 'var(--card-bg)';
        visualizerCtx.fillRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
        
        // Draw bars
        const barCount = 60; // Number of bars to display
        const barWidth = visualizerCanvas.width / barCount;
        const barSpacing = 2;
        const maxBarHeight = visualizerCanvas.height - 20;
        
        for (let i = 0; i < barCount; i++) {
            // Map frequency data to bars (use multiple bins per bar for smoother visualization)
            const dataIndex = Math.floor((i / barCount) * visualizerDataArray.length);
            const barHeight = (visualizerDataArray[dataIndex] / 255) * maxBarHeight;
            
            // Create gradient for bars
            const gradient = visualizerCtx.createLinearGradient(0, visualizerCanvas.height, 0, visualizerCanvas.height - barHeight);
            gradient.addColorStop(0, '#4CAF50'); // Green at bottom
            gradient.addColorStop(0.5, '#FFC107'); // Yellow in middle
            gradient.addColorStop(1, '#FF5722'); // Red at top
            
            // Draw bar
            const x = i * (barWidth + barSpacing);
            visualizerCtx.fillStyle = gradient;
            visualizerCtx.fillRect(x, visualizerCanvas.height - barHeight, barWidth - barSpacing, barHeight);
        }
        
        // Continue animation
        visualizerAnimationId = requestAnimationFrame(drawAudioVisualizer);
    }
    
    function stopAudioVisualizer() {
        // Stop animation
        if (visualizerAnimationId) {
            cancelAnimationFrame(visualizerAnimationId);
            visualizerAnimationId = null;
        }
        
        // Hide visualizer container
        const visualizerContainer = document.getElementById('audio-visualizer-container');
        if (visualizerContainer) {
            visualizerContainer.style.display = 'none';
        }
        
        // Clear canvas
        if (visualizerCanvas && visualizerCtx) {
            visualizerCtx.clearRect(0, 0, visualizerCanvas.width, visualizerCanvas.height);
        }
    }

    function moveToReviewPhase() {
        if (interviewEnded) return;
        clearInterval(answeringTimer);
        clearTimeout(noAnswerTimeout);
        document.getElementById('answering-timer').style.display = 'none';
        document.getElementById('done-btn').style.display = 'none';
        
        // Stop audio visualizer (only for technical interview)
        stopAudioVisualizer();
        
        // ‚úÖ Check if we have transcript before stopping
        const currentTranscript = getFullTranscript();
        
        if (!currentTranscript && isRecordingActive) {
            // No transcript yet but recording is active - wait for Deepgram to send final transcript
            console.log('‚è≥ Waiting for Deepgram to finalize transcript (1 second)...');
            setTimeout(() => {
                // Check again after delay
                const finalTranscript = getFullTranscript();
                if (!finalTranscript) {
                    console.log('‚ö†Ô∏è Still no transcript after wait - Deepgram may not have detected speech');
                    console.log('   Possible reasons:');
                    console.log('   - Audio quality too poor');
                    console.log('   - Microphone not capturing properly');
                    console.log('   - Deepgram connection issues');
                } else {
                    console.log('‚úÖ Transcript received after wait:', finalTranscript.substring(0, 50) + '...');
                }
                stopRecordingAndProcessing();
                sendAudioToServer();
            }, 1000); // Wait 1 second for Deepgram to send final transcript
            return; // Exit early, will continue in setTimeout
        }
        
        stopRecordingAndProcessing();
        // Send transcript to server after stopping recording
        sendAudioToServer();
    }
    
    function startReviewTimer() {
        if (interviewEnded) return;
        let timeLeft = REVIEW_TIME;
        const review = document.getElementById('review-timer-display');
        const reviewTimerValue = document.getElementById('review-timer-value');
        if (review) {
            review.style.display = 'flex';
            review.style.animation = 'fadeInUp 0.5s ease-out';
        }
        
        // Update status
        // Status update removed - using simple UI
        
        reviewInterval = setInterval(() => {
            if (reviewTimerValue) {
                reviewTimerValue.textContent = `${formatTime(timeLeft)}`;
            }
            timeLeft--;
            if (timeLeft < 0) { 
                clearInterval(reviewInterval); 
                if (review) review.style.display = 'none';
                if (statusText) {
                    statusText.textContent = 'Preparing next question...';
                }
                nextSpokenQuestion(); 
            }
        }, 1000);
    }
    
    async function startRecordingAndMonitoring() {
        if (interviewEnded) return;
        audioChunks = [];
        deepgramPartialText = ''; // Clear transcript when starting NEW recording session
        accumulatedFinalText = ''; // Clear accumulated final text for new session
        lastProcessedTranscript = ''; // Reset tracking
        lastKnownTranscript = ''; // Clear backup transcript for new session
        isRecordingActive = true; // Mark recording as active
        
        // Clear any existing transcript timeout
        clearTranscriptTimeout();
        
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: false,
                    noiseSuppression: false,
                    autoGainControl: false,
                    sampleRate: 16000,
                    channelCount: 1
                }
            });
            
            // Initialize audio context for volume monitoring
            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            micSource = audioContext.createMediaStreamSource(stream);
            
            // Create analyser node for audio visualizer (only for technical interview)
            audioAnalyser = audioContext.createAnalyser();
            audioAnalyser.fftSize = 256; // Number of frequency bins
            audioAnalyser.smoothingTimeConstant = 0.8; // Smoothing factor
            micSource.connect(audioAnalyser);
            
            scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
            
            // Volume monitoring for silence detection
            scriptProcessor.onaudioprocess = e => {
                const input = e.inputBuffer.getChannelData(0);
                let sum = 0.0;
                for (let i = 0; i < input.length; ++i) { sum += input[i] * input[i]; }
                const volume = Math.sqrt(sum / input.length);

                if (volume > 0.015) {
                    if (!hasStartedSpeaking) startAnsweringPhase();
                    if (hasStartedSpeaking) silenceDetector.counter = 0;
                } else {
                    if (hasStartedSpeaking) silenceDetector.counter++;
                }

                // CRITICAL: DO NOT automatically move to review phase on silence
                // Users need to be able to pause while speaking without losing their transcript
                // Only move to review phase when:
                // 1. User explicitly clicks "Done" button
                // 2. Time limit is reached
                // 3. NOT on silence detection (removed automatic trigger)
                // This prevents transcript erasure when user pauses mid-sentence
                // if (silenceDetector.counter > silenceDetector.threshold) {
                //     if (!interviewEnded) {
                //        moveToReviewPhase();
                //        silenceDetector.counter = 0;
                //     }
                // }
                
                // Send audio to Deepgram WebSocket
                if (deepgramWS && deepgramWS.readyState === WebSocket.OPEN) {
                    // Convert Float32 to Int16
                    const int16Buffer = new Int16Array(input.length);
                    for (let i = 0; i < input.length; i++) {
                        const s = Math.max(-1, Math.min(1, input[i]));
                        int16Buffer[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                    }
                    deepgramWS.send(int16Buffer.buffer);
                }
            };
            micSource.connect(scriptProcessor);
            scriptProcessor.connect(audioContext.destination);
            
            // Connect to Deepgram WebSocket
            await connectDeepgram(stream);
            
        } catch (err) {
            console.error('Microphone error:', err);
            const transcriptionContent = document.getElementById('transcription-content');
            if (transcriptionContent) {
                transcriptionContent.innerHTML = `<span class="error" style="color: var(--danger-color);">Microphone access denied.</span>`;
            }
        }
    }
    
    async function connectDeepgram(stream) {
        const sampleRate = audioContext.sampleRate || 16000;
        // ‚úÖ Use Django WebSocket proxy instead of direct Deepgram connection
        // This keeps API key secure on backend and works better with Cloud Run
        const wsProto = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const wsUrl = `${wsProto}//${window.location.host}/dg_ws`;
        
        console.log('üîß Connecting to Django Deepgram proxy:', wsUrl);
        console.log('   - sample_rate:', sampleRate);
        console.log('   - model: nova-3');
        console.log('   - language: en-IN');
        
        return new Promise((resolve, reject) => {
            deepgramWS = new WebSocket(wsUrl);
            deepgramWS.binaryType = 'arraybuffer';
            
            deepgramWS.onopen = () => {
                console.log('‚úÖ Connected to Django Deepgram proxy');
                // Send config first (required by Django proxy)
                const config = {
                    sample_rate: sampleRate,
                    model: 'nova-3',
                    language: 'en-IN'
                };
                deepgramWS.send(JSON.stringify(config));
                console.log('üì§ Sent config to proxy:', config);
                resolve();
            };
            
            deepgramWS.onmessage = (event) => {
                // Check if it's a Connected message from proxy
                try {
                    const data = JSON.parse(event.data);
                    if (data.type === 'Connected') {
                        console.log('‚úÖ Proxy confirmed connection');
                        return;
                    }
                } catch (e) {
                    // Not JSON, treat as Deepgram message
                }
                handleDeepgramMessage(event);
            };
            
            deepgramWS.onerror = (error) => {
                console.error('‚ùå Deepgram WebSocket proxy error:', error);
                reject(error);
            };
            
            deepgramWS.onclose = (event) => {
                console.log('üîå Deepgram WebSocket proxy closed:', event.code, event.reason);
            };
        });
    }
    
    // ‚úÖ FIXED TRANSCRIPT HANDLING: Simplified state with single source of truth
    function handleDeepgramMessage(event) {
        try {
            const data = JSON.parse(event.data);
            
            if (data.type === 'Results' && 
                data.channel?.alternatives?.[0]) {
                
                const result = data.channel.alternatives[0];
                const transcript = result.transcript || '';
                const isFinal = !!data.is_final;
                
                if (transcript.trim()) {
                    lastUpdateTime = Date.now();
                    hasEverReceivedText = true;
                    
                    // CRITICAL: Ensure hasStartedSpeaking is set when we receive first transcript
                    // This prevents "no voice detected" message at the start
                    if (!hasStartedSpeaking && transcript.trim().length > 0) {
                        startAnsweringPhase();
                    }
                    
                    if (isFinal) {
                        // ‚úÖ FINAL: Append to accumulated (never replace)
                        console.log(`‚úÖ FINAL: "${transcript}"`);
                        
                        if (!accumulatedTranscript.includes(transcript)) {
                            accumulatedTranscript = accumulatedTranscript 
                                ? `${accumulatedTranscript} ${transcript}`.trim()
                                : transcript;
                        }
                        
                        // Sync legacy variables
                        syncTranscriptVariables();
                        
                        // Update display
                        updateDisplay(accumulatedTranscript);
                    } else {
                        // ‚úÖ INTERIM: Show combined (accumulated + current interim)
                        console.log(`üìù INTERIM: "${transcript}"`);
                        
                        // Deepgram interims are cumulative for current utterance
                        // Display: accumulated + new interim (without duplicating)
                        const displayText = accumulatedTranscript
                            ? `${accumulatedTranscript} ${transcript}`.trim()
                            : transcript;
                        
                        // Store current interim for display
                        currentUtterance = transcript;
                        
                        // Sync legacy variables
                        syncTranscriptVariables();
                        
                        // Update display with combined text
                        updateDisplay(displayText);
                        return; // Don't update accumulated yet (wait for final)
                    }
                }
                // ‚úÖ CRITICAL: Empty transcript = do nothing (preserve existing)
            }
        } catch (err) {
            console.error('‚ùå Parse error:', err);
        }
    }
    
    // ‚úÖ FIXED DISPLAY UPDATES: Proper HTML escaping and state handling
    function updateDisplay(text) {
        const transcriptionContent = document.getElementById('transcription-content');
        if (!transcriptionContent) return;
        
        // ‚úÖ ESCAPE HTML (prevent URL auto-styling)
        const safeText = text
            .replace(/&/g, '&amp;')
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;');
        
        if (safeText.trim()) {
            // Simple display - just show the transcription text
            transcriptionContent.innerHTML = `<span style="color: var(--text-primary); line-height: 1.6;">${safeText}</span>`;
        } else if (isRecordingActive) {
            // Show "Listening..." only if no text yet
            transcriptionContent.innerHTML = `<span style="color: var(--text-secondary);">Listening...</span>`;
        }
    }
    
    // Legacy function name for compatibility
    function updateLiveTranscript() {
        const fullText = getFullTranscript();
        if (fullText) {
            updateDisplay(fullText);
        } else {
            // Show current interim if available
            const displayText = accumulatedTranscript
                ? `${accumulatedTranscript} ${currentUtterance}`.trim()
                : currentUtterance;
            updateDisplay(displayText);
        }
    }

    function stopRecordingAndProcessing() {
        // Mark recording as inactive
        isRecordingActive = false;
        
        // Hide recording indicator
        const recordingIndicator = document.getElementById('recording-indicator');
        if (recordingIndicator) {
            recordingIndicator.style.display = 'none';
        }
        
        // Stop silence monitoring
        stopSilenceMonitoring();
        
        // NOTE: We keep the transcript (accumulatedTranscript) so it can be submitted
        // Only clear when starting a new recording session
        
        // Stop audio visualizer (only for technical interview)
        stopAudioVisualizer();
        
        // Close Deepgram WebSocket
        if (deepgramWS && deepgramWS.readyState === WebSocket.OPEN) {
            deepgramWS.close();
            deepgramWS = null;
        }
        // Close audio context
        if (audioContext) { 
            audioContext.close().catch(e => {}); 
            audioContext = null; 
        }
        // Stop script processor
        if (scriptProcessor) {
            scriptProcessor.disconnect();
            scriptProcessor = null;
        }
        // Stop media stream tracks
        if (micSource && micSource.mediaStream) {
            micSource.mediaStream.getTracks().forEach(track => track.stop());
        }
        
        // Clean up visualizer variables
        audioAnalyser = null;
        visualizerCanvas = null;
        visualizerCtx = null;
        visualizerDataArray = null;
    }

    async function sendAudioToServer() {
        const transcriptionContent = document.getElementById('transcription-content');
        const fd = new FormData();
        fd.append('session_id', INTERVIEW_SESSION_ID);
        const currentQuestion = spokenQuestions[currentSpokenQuestionIndex];
        if (currentQuestion && currentQuestion.id) {
            fd.append('question_id', currentQuestion.id);
        }
        const responseTime = (new Date() - questionStartTime) / 1000;
        fd.append('response_time', responseTime);
        
        // ‚úÖ Wait briefly for final results from Deepgram
        let answerText = getFullTranscript();
        
        if (!answerText.trim()) {
            console.log('‚è≥ Waiting for final transcript...');
            await new Promise(resolve => setTimeout(resolve, 1000));
            answerText = getFullTranscript();
        }
        
        // ‚úÖ Always return accumulated (never empty unless truly no speech)
        if (!answerText.trim()) {
            answerText = 'No speech was detected.';
            console.log('‚ö†Ô∏è No transcript available after wait - showing "No speech was detected"');
            console.log('   This may occur if:');
            console.log('   1. Microphone not capturing audio');
            console.log('   2. Audio quality too poor for Deepgram to process');
            console.log('   3. Deepgram WebSocket connection issues');
        }
        
        // Send transcript to server (simulating the old transcribe_audio endpoint)
        fd.append('transcript', answerText);
        fd.append('transcribed_answer', answerText);
        
        // Display transcript with proper HTML escaping
        const transcriptText = answerText
            .replace(/</g, '&lt;')
            .replace(/>/g, '&gt;')
            .replace(/&/g, '&amp;');
        // Reuse transcriptionContent from line 2795 (already declared)
        if (transcriptionContent) {
            const safeText = transcriptText
                .replace(/&/g, '&amp;')
                .replace(/</g, '&lt;')
                .replace(/>/g, '&gt;');
            transcriptionContent.innerHTML = `<span class='status-indicator status-success'></span><span style="color: var(--text-primary) !important; line-height: 1.6;">${safeText}</span>`;
        }
        
        let result = null; // Declare outside try block for access in finally
        try {
            // Send transcript to AI bot endpoint for processing (handles empty transcripts via LLM)
            // This endpoint processes the answer and generates next question using AI
            const res = await fetch("{% url 'ai_upload_answer' %}", { 
                method: 'POST', 
                body: fd 
            });
            if (!res.ok) { 
                const err = await res.json(); 
                throw new Error(err.error || `Server Error ${res.status}`); 
            }
            result = await res.json();
            
            console.log('üì• Backend response:', result);
            
            // Handle acknowledgment response (for empty transcripts)
            // When backend returns acknowledge=true, it means empty transcript was detected
            // and LLM decided to ask again (not move to next question)
            // This will restart recording for the SAME question
            if (result.acknowledge && result.message) {
                console.log('‚ö†Ô∏è Acknowledgment response - empty transcript detected');
                console.log('   Message:', result.message);
                
                // Play acknowledgment audio if available
                if (result.audio_url) {
                    const acknowledgeAudio = new Audio(result.audio_url);
                    acknowledgeAudio.onended = () => {
                        // After acknowledgment, restart recording for same question
                        // Reset transcript for new attempt
                        resetTranscript();
                        hasStartedSpeaking = false;
                        // Restart answering phase
                        startAnsweringPhase();
                    };
                    acknowledgeAudio.play().catch(e => {
                        console.error('Error playing acknowledgment audio:', e);
                        // Fallback: restart recording after 2 seconds
                        setTimeout(() => {
                            resetTranscript();
                            hasStartedSpeaking = false;
                            startAnsweringPhase();
                        }, 2000);
                    });
                } else {
                    // No audio URL - just restart recording after showing message
                    setTimeout(() => {
                        resetTranscript();
                        hasStartedSpeaking = false;
                        startAnsweringPhase();
                    }, 2000);
                }
                
                // Show acknowledgment message in UI
                const transcriptionContent = document.getElementById('transcription-content');
                if (transcriptionContent) {
                    transcriptionContent.innerHTML = `<span class='status-indicator status-waiting'></span><strong style="color: var(--text-primary);">${result.message}</strong>`;
                }
                return; // Don't start review timer - waiting for user to try again
            }
            
            // Handle completion response
            if (result.completed) {
                console.log('‚úÖ Interview completed');
                interviewEnded = true;
                stopRecordingAndProcessing();
                
                // Display closing message to user
                const closingMessage = result.message || result.next_question || "Interview completed. Thank you for your time!";
                
                // Update AI message display with closing statement
                // Update question container with closing message
                const questionContainer = document.getElementById('question-container');
                const questionTextEl = document.getElementById('question-text');
                if (questionContainer && questionTextEl) {
                    questionContainer.style.display = 'block';
                    questionTextEl.textContent = closingMessage;
                }
                
                // Also update transcription content
                const transcriptionContent = document.getElementById('transcription-content');
                if (transcriptionContent) {
                    transcriptionContent.innerHTML = `<strong style="color: var(--text-primary); font-size: 1.1rem;">${closingMessage}</strong>`;
                }
                
                // Hide timers and show completion message
                const thinkingTimerEl = document.getElementById('thinking-timer');
                const answeringTimerEl = document.getElementById('answering-timer');
                const reviewTimerEl = document.getElementById('review-timer');
                if (thinkingTimerEl) thinkingTimerEl.style.display = 'none';
                if (answeringTimerEl) answeringTimerEl.style.display = 'none';
                if (reviewTimerEl) reviewTimerEl.style.display = 'none';
                
                // Play closing statement audio if available, then automatically end the interview
                if (result.audio_url) {
                    console.log('üîä Playing closing statement audio...');
                    const closingAudio = new Audio(result.audio_url);
                    closingAudio.onended = () => {
                        console.log('‚úÖ Closing statement audio finished');
                        // After audio finishes, wait a moment then end the interview
                        setTimeout(() => {
                            console.log('üèÅ Ending interview session automatically...');
                            endSpokenOnlyInterview();
                        }, 1000); // 1 second after audio ends
                    };
                    closingAudio.onerror = (e) => {
                        console.error('‚ùå Error playing closing audio:', e);
                        // If audio fails, end interview after 3 seconds
                        setTimeout(() => {
                            console.log('üèÅ Ending interview session automatically (audio failed)...');
                            endSpokenOnlyInterview();
                        }, 3000);
                    };
                    closingAudio.play().catch(e => {
                        console.error('‚ùå Error playing closing audio:', e);
                        // If play fails, end interview after 3 seconds
                        setTimeout(() => {
                            console.log('üèÅ Ending interview session automatically (play failed)...');
                            endSpokenOnlyInterview();
                        }, 3000);
                    });
                } else {
                    // No audio - just wait 3 seconds then end
                    console.log('‚è≥ No closing audio, waiting 3 seconds before ending interview session...');
                    setTimeout(() => {
                        console.log('üèÅ Ending interview session automatically...');
                        endSpokenOnlyInterview();
                    }, 3000);
                }
                
                return;
            }
            
            // Handle interviewer answer to candidate question (if candidate asked a question)
            if (result.interviewer_answer) {
                console.log('üí¨ Interviewer answering candidate question:', result.interviewer_answer);
                
                // Display the interviewer's answer in the AI message container
                // Display the interviewer's answer in the question container
                const questionContainer = document.getElementById('question-container');
                const questionTextEl = document.getElementById('question-text');
                if (questionContainer && questionTextEl) {
                    questionContainer.style.display = 'block';
                    questionTextEl.textContent = result.interviewer_answer;
                }
                
                // Also update transcription content to show the answer
                const transcriptionContent = document.getElementById('transcription-content');
                if (transcriptionContent) {
                    transcriptionContent.innerHTML = `<strong style="color: var(--text-primary);">Interviewer: ${result.interviewer_answer}</strong>`;
                }
                
                // Play answer audio if available, then proceed to next question
                if (result.answer_audio_url) {
                    console.log('üîä Playing interviewer answer audio...');
                    const answerAudio = new Audio(result.answer_audio_url);
                    answerAudio.onended = () => {
                        console.log('‚úÖ Answer audio finished, proceeding to next question...');
                        // After answer audio finishes, proceed to display next question
                        handleNextQuestionAfterAnswer(result);
                    };
                    answerAudio.onerror = (e) => {
                        console.error('‚ùå Error playing answer audio:', e);
                        // If audio fails, proceed anyway
                        handleNextQuestionAfterAnswer(result);
                    };
                    answerAudio.play().catch(e => {
                        console.error('‚ùå Error playing answer audio:', e);
                        // If play fails, proceed anyway
                        handleNextQuestionAfterAnswer(result);
                    });
                } else {
                    // No audio - proceed to next question after short delay
                    setTimeout(() => {
                        handleNextQuestionAfterAnswer(result);
                    }, 2000);
                }
            } else {
                // No interviewer answer - proceed directly to next question
                handleNextQuestionAfterAnswer(result);
            }
        } catch (err) {
            console.error('Error sending transcript to server:', err);
            // Still show the transcript even if server save fails
        } finally {
            // Only start review timer if NOT an acknowledgment response
            // Acknowledgment responses restart recording immediately
            if (!result || !result.acknowledge) {
                startReviewTimer();
            }
        }
    }
    
    function handleNextQuestion(result) {
            // Handle next question response
            if (result.next_question) {
                console.log('üìù Next question received');
                
                // Add next question to spoken questions list
                const nextQuestion = {
                    id: result.question_id || null,
                    text: result.next_question,
                    type: result.question_type || 'TECHNICAL',
                    audio_url: result.audio_url || null
                };
                
                // Insert next question after current question
                spokenQuestions.splice(currentSpokenQuestionIndex + 1, 0, nextQuestion);
                
                // Also save follow-up question if provided
                if (result.follow_up_question) {
                    spokenQuestions.splice(currentSpokenQuestionIndex + 2, 0, result.follow_up_question);
                }
            
            // Display the next question with smooth transition
            currentSpokenQuestionIndex++;
            // Small delay to ensure smooth transition
            setTimeout(() => {
                displayCurrentQuestion();
            }, 100);
            
            // Play question audio if available
            if (result.audio_url) {
                const questionAudio = new Audio(result.audio_url);
                questionAudio.onended = () => {
                    console.log('‚úÖ Question audio finished');
                    startAnsweringPhase();
                };
                questionAudio.onerror = (e) => {
                    console.error('‚ùå Error playing question audio:', e);
                    startAnsweringPhase();
                };
                questionAudio.play().catch(e => {
                    console.error('‚ùå Error playing question audio:', e);
                    startAnsweringPhase();
                });
            } else {
                // No audio - start answering phase after short delay
                setTimeout(() => {
                    startAnsweringPhase();
                }, 1000);
            }
        }
    }
    
    // Helper function to handle next question after interviewer answers candidate question
    function handleNextQuestionAfterAnswer(result) {
        // Same logic as handleNextQuestion - handles next question after answering candidate
        handleNextQuestion(result);
    }

    function startCodingPhase() {
        // Ensure audio recording is active for coding phase (don't restart if already recording)
        if (!audioRecorder || !audioRecorder.isRecording) {
            // CRITICAL: Only start audio if video timestamp is available
            if (window.videoStartTimestamp) {
                console.log("üéôÔ∏è Starting audio recording for coding phase with video timestamp...");
                startAudioRecording(0, window.videoStartTimestamp);
            } else {
                console.warn("‚ö†Ô∏è Video timestamp not available - NOT starting audio to avoid desync");
            }
        } else {
            console.log("‚úÖ Audio recording already active, continuing through coding phase");
        }
        console.log("Transitioning to coding phase...");
        
        // Backend video recording continues automatically (started at technical interview start)
        console.log("‚úÖ Backend video recording continues through coding phase");
        
        stopRecordingAndProcessing();
        clearTimeout(noAnswerTimeout);
        clearInterval(thinkingTimer); clearInterval(answeringTimer); clearInterval(reviewInterval);

        // Hide spoken phase and setup
        const spokenPhase = document.getElementById('spoken-interview-phase');
        const setupPhase = document.getElementById('setup-phase');
        const questionContainer = document.getElementById('question-container');
        
        if (spokenPhase) spokenPhase.style.display = 'none';
        if (setupPhase) setupPhase.style.display = 'none';
        if (questionContainer) questionContainer.style.display = 'none';

        // Show coding phase
        const codingPhase = document.getElementById('coding-interview-phase');
        if (codingPhase) {
            // Use grid to match technical interview layout (content + right sidebar)
            codingPhase.style.display = 'grid';
            console.log('‚úÖ Coding phase div displayed');
        } else {
            console.error('‚ùå coding-interview-phase div not found!');
            return;
        }

        if (codingQuestions.length === 0) {
            console.warn('No coding questions available. Checking database...');
            // Still show the coding phase UI but with a message
            document.getElementById('coding-question-title').innerText = 'No Coding Question Available';
            document.getElementById('coding-problem-text').innerText = 'Please contact support.';
            return;
        }

        // Ensure proctoring camera is active for coding phase (using backend MJPEG stream)
        try {
            // Ensure warnings list is visible and ready
            const warningsList2 = document.getElementById('warnings-list-2');
            if (warningsList2) {
                warningsList2.innerHTML = ''; // Clear any old warnings
                console.log('‚úÖ Coding warnings list cleared and ready');
            }
            
            // Update session ID for coding phase
            if (SESSION_KEY) {
                const sessionIdCoding = document.getElementById('proctoring-session-id-coding');
                if (sessionIdCoding) {
                    const sessionIdDisplay = SESSION_KEY.length > 8 ? SESSION_KEY.substring(0, 8) : SESSION_KEY;
                    sessionIdCoding.textContent = sessionIdDisplay;
                }
            }
            
            // Restart proctoring monitors - this will set up both feeds via backend
            startProctoringMonitors(); 
            console.log('‚úÖ Proctoring monitors restarted for coding phase');
            
            // Ensure timestamp continues (don't reset, just continue from where it was)
            if (!timestampInterval) {
                startProctoringTimestamps();
            }
            
            // Force an immediate warning check after a brief delay
            setTimeout(() => {
                const codingPhase = document.getElementById('coding-interview-phase');
                if (codingPhase && codingPhase.style.display !== 'none') {
                    console.log('üîç Coding phase confirmed active - warnings should start updating');
                    // The interval is already running from startProctoringMonitors()
                }
            }, 500);
        } catch(e) { 
            console.error('‚ùå Proctoring restart error:', e?.message); 
        }
        
        // Start the 20-minute countdown timer
        startCodingTimer();
        
        // Load the first coding question
        nextCodingQuestion();
    }
    
    function startCodingTimer() {
        // Reset timer to 20 minutes
        codingTimeRemaining = 20 * 60;
        
        // Clear any existing timer
        if (codingTimerInterval) {
            clearInterval(codingTimerInterval);
        }
        
        // Update timer display immediately
        updateCodingTimerDisplay();
        
        // Start countdown interval (update every second)
        codingTimerInterval = setInterval(() => {
            codingTimeRemaining--;
            updateCodingTimerDisplay();
            
            if (codingTimeRemaining <= 0) {
                clearInterval(codingTimerInterval);
                handleCodingTimerExpired();
            } else if (codingTimeRemaining <= 300) { // Last 5 minutes
                // Change color to red for last 5 minutes
                const timerEl = document.getElementById('coding-timer');
                if (timerEl) {
                    timerEl.style.background = 'linear-gradient(135deg, #f44336 0%, #d32f2f 100%)';
                    timerEl.style.animation = 'pulse 1s infinite';
                }
            }
        }, 1000);
    }
    
    function updateCodingTimerDisplay() {
        const timerEl = document.getElementById('coding-timer');
        if (!timerEl) return;
        
        const minutes = Math.floor(codingTimeRemaining / 60);
        const seconds = codingTimeRemaining % 60;
        const timeString = `${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
        
        timerEl.innerHTML = `‚è±Ô∏è ${timeString}`;
    }
    
    function handleCodingTimerExpired() {
        const timerEl = document.getElementById('coding-timer');
        if (timerEl) {
            timerEl.innerHTML = '‚è±Ô∏è 00:00';
            timerEl.style.background = 'linear-gradient(135deg, #f44336 0%, #d32f2f 100%)';
        }
        
        // Disable buttons
        const runBtn = document.getElementById('run-code-btn');
        const submitBtn = document.getElementById('submit-code-btn');
        if (runBtn) runBtn.disabled = true;
        if (submitBtn) submitBtn.disabled = true;
        
        // Show warning
        alert('‚è±Ô∏è Time is up! Your code will be auto-submitted now.');
        
        // Auto-submit current code if available
        const currentQuestion = codingQuestions[currentCodingQuestionIndex];
        if (currentQuestion && monacoEditor) {
            submitCurrentCode(currentQuestion);
        }
    }

    function nextCodingQuestion() {
        console.log('üìù nextCodingQuestion called, index:', currentCodingQuestionIndex, 'total:', codingQuestions.length);
        
        if (codingQuestions.length === 0) {
            console.error('‚ùå No coding questions available!');
            document.getElementById('coding-question-title').innerText = 'No Coding Question Available';
            document.getElementById('coding-problem-text').innerText = 'Please contact support.';
            return;
        }

        currentCodingQuestionIndex++;

        if (currentCodingQuestionIndex >= codingQuestions.length) {
            console.log("All coding challenges completed.");
            
            // Stop audio recording before redirecting
            if (audioRecorder && audioRecorder.isRecording) {
                audioRecorder.stopRecording().then(() => {
                    console.log('‚úÖ Audio recording stopped and uploaded');
            window.location.href = "{% url 'interview_complete' %}?session_key=" + SESSION_KEY;
                }).catch(err => {
                    console.error('‚ùå Error stopping audio recording:', err);
                    window.location.href = "{% url 'interview_complete' %}?session_key=" + SESSION_KEY;
                });
            } else {
                window.location.href = "{% url 'interview_complete' %}?session_key=" + SESSION_KEY;
            }
            return;
        }

        const codingQuestion = codingQuestions[currentCodingQuestionIndex];
        console.log('‚úÖ Loading coding question:', codingQuestion.title, 'ID:', codingQuestion.id);
        
        document.getElementById('coding-question-title').innerText = codingQuestion.title || 'Coding Challenge';
        document.getElementById('coding-language-display').innerText = `Language: ${codingQuestion.language}`;
        document.getElementById('coding-problem-text').innerText = codingQuestion.description || codingQuestion.text || 'No description available.';
        document.getElementById('code-output-pre').innerHTML = "";
        // ======================
        // NEW: Show test cases table above code editor
        const testCasesContainerId = 'coding-test-cases-table';
        let tcHtml = `<h4 style="color: #667eea;">üî¨ Test Cases:</h4><table id='${testCasesContainerId}' style="width:100%; border-collapse:collapse; background:#f9f9fa; margin-bottom:16px;">
                <tr style='background:#f2f2f2;'><th style='padding:5px;border:1px solid #ddd;'>#</th><th style='padding:5px;border:1px solid #ddd;'>Input</th><th style='padding:5px;border:1px solid #ddd;'>Expected Output</th><th style='padding:5px;border:1px solid #ddd;'>Result</th></tr>`;
        (codingQuestion.test_cases||[]).forEach((tc, idx) => {
            tcHtml += `<tr><td style='padding:4px 8px; border:1px solid #ddd;'>${idx+1}</td><td style='padding:4px 8px; border:1px solid #ddd;'><code>${tc.input}</code></td><td style='padding:4px 8px; border:1px solid #ddd;'><code>${tc.expected_output||tc.output}</code></td><td style='border:1px solid #ddd;' id='tc-result-${idx}'></td></tr>`
        });
        tcHtml += `</table>`;
        const probDiv = document.getElementById('coding-problem-container');
        if (!document.getElementById(testCasesContainerId)) {
          probDiv.insertAdjacentHTML('beforeend', tcHtml);
        } else {
          document.getElementById(testCasesContainerId).outerHTML = tcHtml;
        }
        // ======================

        const submitBtn = document.getElementById('submit-code-btn');
        if (currentCodingQuestionIndex === codingQuestions.length - 1) {
            submitBtn.innerText = "Submit & End Interview";
        } else {
            submitBtn.innerText = "Submit & Next Challenge";
        }
        submitBtn.disabled = false;

        if (!monacoEditor) {
            require.config({ paths: { 'vs': 'https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.33.0/min/vs' }});
            require(['vs/editor/editor.main'], function() {
                const initialCode = codingQuestion.starter_code || `// Your ${codingQuestion.language} code here...`;
                monacoEditor = monaco.editor.create(document.getElementById('monaco-editor-container'), {
                    value: initialCode,
                    language: codingQuestion.language.toLowerCase(),
                    theme: 'vs-dark'
                });
            });
        } else {
            monacoEditor.setValue(codingQuestion.starter_code || `// Your ${codingQuestion.language} code here...`);
            monaco.editor.setModelLanguage(monacoEditor.getModel(), codingQuestion.language.toLowerCase());
        }

        const runBtn = document.getElementById('run-code-btn');
        const newRunBtn = runBtn.cloneNode(true);
        runBtn.parentNode.replaceChild(newRunBtn, runBtn);
        newRunBtn.addEventListener('click', () => runCode(codingQuestion));
        
        const newSubmitBtn = submitBtn.cloneNode(true);
        submitBtn.parentNode.replaceChild(newSubmitBtn, submitBtn);
        newSubmitBtn.addEventListener('click', () => submitCurrentCode(codingQuestion));
    }

    async function runCode(question) {
        const outputEl = document.getElementById('code-output-pre');
        const runBtn = document.getElementById('run-code-btn');
        const originalText = runBtn.innerText;
        
        runBtn.disabled = true;
        runBtn.innerText = "Running...";
        outputEl.innerHTML = '<span style="color: #4CAF50;">‚è≥ Running test cases...</span>';
        
        const code = monacoEditor.getValue();

        try {
            // Add timeout abort controller - increased to 120 seconds to handle multiple test cases safely
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 120000); // 120 second timeout for multiple test cases

            const response = await fetch("{% url 'execute_code' %}?session_key=" + SESSION_KEY, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    code: code,
                    language: question.language,
                    question_id: question.id,
                    session_key: SESSION_KEY,
                }),
                signal: controller.signal
            });
            
            clearTimeout(timeoutId);
            
            if (!response.ok) {
                throw new Error(`Server error: ${response.status}`);
            }
            
            const result = await response.json();
            
            // Format output with test case results
            let outputHTML = '';
            const resultTestCases = (question.test_cases || []);
            let perTestStatus = [];
            if (result.output) {
                const lines = result.output.split('\n');
                let inTestCase = false;
                let testIndex = 0;
                // Try to match pass/fail per test
                lines.forEach(line => {
                    if (line.includes('Test Case') && (line.includes('PASSED') || line.includes('FAILED'))) {
                        const isPassed = line.includes('PASSED');
                        perTestStatus.push(isPassed);
                        const color = isPassed ? '#4CAF50' : '#f44336';
                        const icon = isPassed ? '‚úÖ' : '‚ùå';
                        outputHTML += `<div style="color: ${color}; font-weight: bold; margin: 5px 0;">${icon} ${line}</div>`;
                        // Update table row for this test
                        const cell = document.getElementById(`tc-result-${testIndex}`);
                        if (cell) cell.innerHTML = `<span style='font-weight:bold; color:${color};'>${icon} ${isPassed?"Pass":"Fail"}</span>`;
                        testIndex += 1;
                        inTestCase = true;
                    } else if (line.trim() && inTestCase) {
                        outputHTML += `<div style="margin-left: 20px; color: #ccc;">${line}</div>`;
                    } else if (line.trim()) {
                        outputHTML += `<div style="color: #fff;">${line}</div>`;
                    }
                });
                // Reset table rows if not updated
                resultTestCases.forEach((tc, idx)=>{
                  if(typeof perTestStatus[idx]==='undefined'){
                    const cell = document.getElementById(`tc-result-${idx}`);
                    if(cell) cell.innerHTML = '';
                  }
                });
                // Show summary
                const passedCount = (result.output.match(/PASSED/g) || []).length;
                const failedCount = (result.output.match(/FAILED/g) || []).length;
                const totalCount = passedCount + failedCount;
                if (totalCount > 0) {
                    outputHTML = `<div style="color: #4CAF50; font-weight: bold; margin-bottom: 10px; padding: 10px; background: rgba(76, 175, 80, 0.07); border-radius: 5px;">\nüìä Test Results: ${passedCount}/${totalCount} passed\n</div>` + outputHTML;
                }
            } else {
                outputHTML = '<span style="color: #ff9800;">‚ö†Ô∏è No test results returned</span>';
            }
            outputEl.innerHTML = outputHTML || result.output || 'No output';
            
        } catch (err) {
            if (err.name === 'AbortError') {
                outputEl.innerHTML = '<span style="color: #f44336;">‚è±Ô∏è Request timed out after 120 seconds. Please check your code for infinite loops or optimize your solution.</span>';
            } else if (err instanceof Error && err.message.startsWith('Server error:')) {
                // Try to fetch the real error message from the response body (if available)
                try {
                    // If we have a response object, get it here (must be in try block above scope)
                    if (typeof err.response !== 'undefined') {
                        err.response.json().then(json => {
                            outputEl.innerHTML = `<span style=\"color: #f44336;\">‚ùå Server Error: ${json.message || JSON.stringify(json) || err.message}</span>`;
                        }).catch(() => {
                            outputEl.innerHTML = `<span style=\"color: #f44336;\">‚ùå ${err.message}</span>`;
                        });
                    } else {
                        outputEl.innerHTML = `<span style=\"color: #f44336;\">‚ùå ${err.message}</span>`;
                    }
                } catch (e) {
                    outputEl.innerHTML = `<span style=\"color: #f44336;\">‚ùå ${err.message}</span>`;
                }
            } else if (typeof err.response !== 'undefined') {
                // Generic fetch error with possible response (older browsers)
                err.response.json().then(json => {
                    outputEl.innerHTML = `<span style=\"color: #f44336;\">‚ùå Error: ${json.message || JSON.stringify(json) || err.message}</span>`;
                }).catch(() => {
                    outputEl.innerHTML = `<span style=\"color: #f44336;\">‚ùå Error: ${err.message}</span>`;
                });
            } else {
                outputEl.innerHTML = `<span style=\"color: #f44336;\">‚ùå Error: ${err.message}</span>`;
            }
        } finally {
            runBtn.disabled = false;
            runBtn.innerText = originalText;
        }
    }

    async function submitCurrentCode(question) {
        const isFinalSubmission = (currentCodingQuestionIndex === codingQuestions.length - 1);
        const confirmationMessage = isFinalSubmission 
            ? "Are you sure you want to submit your code? This will end the interview."
            : "Are you sure you want to submit this answer and move to the next challenge?";
        
        if (!confirm(confirmationMessage)) return;

        const submitBtn = document.getElementById('submit-code-btn');
        const originalText = submitBtn.innerText;
        submitBtn.disabled = true;
        submitBtn.innerText = "Submitting...";
        const code = monacoEditor.getValue();
        
        // Show submission status in output
        const outputEl = document.getElementById('code-output-pre');
        outputEl.innerHTML = '<span style="color: #4CAF50;">‚è≥ Submitting code and running final tests...</span>';

        try {
            // Add timeout for submission - increased for multiple test cases
            const controller = new AbortController();
            const timeoutId = setTimeout(() => controller.abort(), 120000); // 120 second timeout for submission

            const response = await fetch("{% url 'submit_coding_challenge' %}", {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    session_key: SESSION_KEY,
                    question_id: question.id,
                    code: code,
                    language: question.language,
                    is_final: isFinalSubmission
                }),
                keepalive: true,
                signal: controller.signal
            });
            
            clearTimeout(timeoutId);
            
            if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                throw new Error(errorData.message || `Server error: ${response.status}`);
            }

            const result = await response.json();
            
            // Show submission result
            if (result.passed_all_tests !== undefined) {
                const statusText = result.passed_all_tests ? '‚úÖ All tests passed!' : '‚ùå Some tests failed';
                outputEl.innerHTML = `<div style="color: ${result.passed_all_tests ? '#4CAF50' : '#f44336'}; font-weight: bold; padding: 10px; background: rgba(76, 175, 80, 0.1); border-radius: 5px;">
                    ${statusText}<br>
                    ${result.output_log ? result.output_log.replace(/\n/g, '<br>') : ''}
                </div>`;
            }

            // Stop timer on successful submission
            if (codingTimerInterval) {
                clearInterval(codingTimerInterval);
                codingTimerInterval = null;
            }
            
            // Release camera and microphone immediately after submission
            try {
                // Stop all media tracks
                if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
                    navigator.mediaDevices.getUserMedia({ video: true, audio: true })
                        .then(stream => {
                            stream.getTracks().forEach(track => {
                                track.stop();
                                console.log('Released media track:', track.kind);
                            });
                        })
                        .catch(err => {
                            console.log('No active media streams to release');
                        });
                }
                
                // Release any existing streams
                if (window.verificationStream) {
                    window.verificationStream.getTracks().forEach(track => track.stop());
                    console.log('Released verification stream');
                }
                
                // Close audio contexts
                if (window.audioContext) {
                    window.audioContext.close().catch(e => console.log('Audio context already closed'));
                    console.log('Closed audio context');
                }
                
                // Stop media recorders
                if (window.mediaRecorder && window.mediaRecorder.state !== 'inactive') {
                    window.mediaRecorder.stop();
                    console.log('Stopped media recorder');
                }
                
        // Release backend camera resources
        fetch("{% url 'release_camera' %}", {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ session_key: SESSION_KEY })
        }).then(() => {
            console.log('Backend camera resources released');
        }).catch(err => {
            console.log('Error releasing backend camera:', err);
        });
                
                console.log('‚úÖ Camera and microphone released after coding submission');
            } catch (error) {
                console.log('Error releasing media resources:', error);
            }
            
            // Small delay to show result, then proceed
            setTimeout(() => {
                if (isFinalSubmission) {
                    releaseMediaResources();
                    
                    // Stop audio recording and end session before redirecting
                    const stopAudioAndRedirect = async () => {
                        let audioPath = null;
                        
                        if (audioRecorder && audioRecorder.isRecording) {
                            try {
                                console.log('üõë Stopping audio recording...');
                                const stopResult = await audioRecorder.stopRecording();
                                console.log('üìä Stop recording result:', stopResult);
                                
                                if (stopResult && stopResult.success && stopResult.audioPath) {
                                    audioPath = stopResult.audioPath;
                                    console.log('‚úÖ Audio path from stopRecording:', audioPath);
                                } else {
                                    console.warn('‚ö†Ô∏è Stop recording did not return audio path, checking stored paths...');
                                    // Fallback: check stored paths
                                    await new Promise(resolve => setTimeout(resolve, 1000));
                                }
                            } catch (err) {
                                console.error('‚ùå Error stopping audio recording:', err);
                            }
                        }
                        
                        // Wait and poll for audio path with multiple attempts
                        const maxAttempts = 10;
                        let attempts = 0;
                        while (!audioPath && attempts < maxAttempts) {
                            attempts++;
                            console.log(`üîç Attempt ${attempts}/${maxAttempts}: Checking for audio path...`);
                            
                            // Check all possible locations
                            audioPath = uploadedAudioPath || window.uploadedAudioPath;
                            if (!audioPath && window.parent && window.parent !== window) {
                                audioPath = window.parent.uploadedAudioPath;
                            }
                            
                            if (!audioPath) {
                                // Wait before next attempt
                                await new Promise(resolve => setTimeout(resolve, 500));
                            } else {
                                console.log('‚úÖ Audio path found:', audioPath);
                                break;
                            }
                        }
                        
                        console.log('üîç Final audio path check:', {
                            fromStopRecording: audioPath,
                            uploadedAudioPath: uploadedAudioPath,
                            windowUploadedAudioPath: window.uploadedAudioPath,
                            parentUploadedAudioPath: (window.parent && window.parent !== window) ? window.parent.uploadedAudioPath : 'N/A',
                            finalAudioPath: audioPath,
                            attempts: attempts
                        });
                        
                        // Prepare end session data with audio path if available
                        const endSessionData = { session_key: SESSION_KEY };
                        
                        if (audioPath) {
                            endSessionData.audio_file_path = audioPath;
                            console.log('üìÅ Including audio file path in end session request:', audioPath);
                        } else {
                            console.warn('‚ö†Ô∏è No audio file path found - video will be saved without audio');
                            console.warn('‚ö†Ô∏è Audio recorder state:', {
                                exists: !!audioRecorder,
                                isRecording: audioRecorder?.isRecording,
                                audioChunks: audioRecorder?.audioChunks?.length
                            });
                        }
                        
                        // CRITICAL: Calculate synchronized stop time for both audio and video
                        // This ensures both stop at the EXACT same moment
                        const synchronizedStopTime = Date.now() / 1000 + 0.2; // 200ms in the future
                        console.log(`üïê Synchronized stop time: ${synchronizedStopTime} (both audio and video will stop at this exact moment)`);
                        
                        // CRITICAL: Stop audio at synchronized time
                        console.log('üõë Stopping audio recording at synchronized time...');
                        const audioStopResult = await audioRecorder.stopRecording(synchronizedStopTime);
                        console.log('üìä Audio stop result:', audioStopResult);
                        
                        // Add synchronized stop time to end session data
                        endSessionData.synchronized_stop_time = synchronizedStopTime;
                        endSessionData.audio_stop_timestamp = audioStopResult.audioStopTimestamp || audioStopTimestamp;
                        
                        // Now end session (which will stop video at the same synchronized time and merge)
                        console.log('üèÅ Ending interview session (will stop video at synchronized time and merge)...');
                        fetch("{% url 'end_interview_session' %}", {
                            method: 'POST',
                            headers: { 'Content-Type': 'application/json' },
                            body: JSON.stringify(endSessionData),
                            keepalive: true
                        }).then(response => {
                            console.log('üì§ End session response status:', response.status);
                            return response.json();
                        }).then(data => {
                            console.log('üì• End session response:', data);
                        }).catch(err => {
                            console.error("‚ùå Error ending session:", err);
                        }).finally(() => {
                    window.location.href = "{% url 'interview_complete' %}?session_key=" + SESSION_KEY;
                        });
                    };
                    
                    stopAudioAndRedirect();
                } else {
                    nextCodingQuestion();
                    submitBtn.disabled = false;
                    submitBtn.innerText = originalText;
                }
            }, 1500);
            
        } catch (err) {
            if (err.name === 'AbortError') {
                outputEl.innerHTML = '<span style="color: #f44336;">‚è±Ô∏è Submission timed out. Please try again.</span>';
                alert("Submission timed out. Please check your connection and try again.");
            } else {
                outputEl.innerHTML = `<span style="color: #f44336;">‚ùå Submission failed: ${err.message}</span>`;
                alert("An error occurred during submission. Please try again.\nError: " + err.message);
            }
            submitBtn.disabled = false;
            submitBtn.innerText = originalText;
        }
    }

    function endSpokenOnlyInterview() {
        if (interviewEnded) return;
        interviewEnded = true;
        console.log("Ending spoken-only interview.");
        
        // Stop audio recording and wait for upload before ending session
        const stopAudioAndEndSession = async () => {
            let audioPath = null;
            
            // Always try to stop recording if it exists (even if not currently recording)
            if (audioRecorder) {
                try {
                    console.log('üõë Stopping audio recording...');
                    console.log('üìä Audio recorder state:', {
                        exists: !!audioRecorder,
                        isRecording: audioRecorder.isRecording,
                        hasChunks: audioRecorder.audioChunks && audioRecorder.audioChunks.length > 0
                    });
                    
                    // CRITICAL: Calculate synchronized stop time for both audio and video
                    const synchronizedStopTime = Date.now() / 1000 + 0.2; // 200ms in the future
                    console.log(`üïê Synchronized stop time: ${synchronizedStopTime}`);
                    
                    // If recording, stop it at synchronized time and wait for upload
                    if (audioRecorder.isRecording) {
                        const stopResult = await audioRecorder.stopRecording(synchronizedStopTime);
                        console.log('üìä Stop recording result:', stopResult);
                        
                        if (stopResult && stopResult.success && stopResult.audioPath) {
                            audioPath = stopResult.audioPath;
                            console.log('‚úÖ Audio path from stopRecording:', audioPath);
                        }
                        
                        // Add synchronized stop time to end session data
                        if (endSessionData) {
                            endSessionData.synchronized_stop_time = synchronizedStopTime;
                            endSessionData.audio_stop_timestamp = stopResult.audioStopTimestamp;
                        }
                    } else if (audioRecorder.audioChunks && audioRecorder.audioChunks.length > 0) {
                        // If not recording but has chunks, process them
                        console.log('üì¶ Audio recorder has chunks but not recording, processing...');
                        await audioRecorder.processRecording();
                        // Wait a bit for upload to complete
                        await new Promise(resolve => setTimeout(resolve, 2000));
                    }
                } catch (err) {
                    console.error('‚ùå Error stopping audio recording:', err);
                }
            }
            
            // Wait and poll for audio path with multiple attempts
            const maxAttempts = 10;
            let attempts = 0;
            while (!audioPath && attempts < maxAttempts) {
                attempts++;
                console.log(`üîç Attempt ${attempts}/${maxAttempts}: Checking for audio path...`);
                
                // Check all possible locations
                audioPath = uploadedAudioPath || window.uploadedAudioPath;
                if (!audioPath && window.parent && window.parent !== window) {
                    audioPath = window.parent.uploadedAudioPath;
                }
                
                if (!audioPath) {
                    // Wait before next attempt
                    await new Promise(resolve => setTimeout(resolve, 500));
                } else {
                    console.log('‚úÖ Audio path found:', audioPath);
                    break;
                }
            }
            
            console.log('üîç Final audio path check:', {
                fromStopRecording: audioPath,
                uploadedAudioPath: uploadedAudioPath,
                windowUploadedAudioPath: window.uploadedAudioPath,
                parentUploadedAudioPath: (window.parent && window.parent !== window) ? window.parent.uploadedAudioPath : 'N/A',
                finalAudioPath: audioPath,
                attempts: attempts
            });
        
        // Release media resources before ending session
        releaseMediaResources();
            
            // Prepare end session data with audio path if available
            const endSessionData = { session_key: SESSION_KEY };
            
            if (audioPath) {
                endSessionData.audio_file_path = audioPath;
                console.log('üìÅ Including audio file path in end session request:', audioPath);
            } else {
                console.warn('‚ö†Ô∏è No audio file path available - video will be saved without audio');
                console.warn('‚ö†Ô∏è Audio recorder state:', {
                    exists: !!audioRecorder,
                    isRecording: audioRecorder?.isRecording,
                    audioChunks: audioRecorder?.audioChunks?.length
                });
            }
        
        fetch("{% url 'end_interview_session' %}", {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify(endSessionData),
            keepalive: true
        })
            .then(response => {
                console.log('üì§ End session response status:', response.status);
                return response.json();
            })
            .then(data => {
                console.log('üì• End session response:', data);
            })
            .catch(err => {
                console.error("‚ùå Error ending session:", err);
            })
        .finally(() => {
            window.location.href = "{% url 'interview_complete' %}?session_key=" + SESSION_KEY;
        });
        };
        
        stopAudioAndEndSession();
    }
    
    async function releaseMediaResources() {
        try {
            // Stop coding timer
            if (codingTimerInterval) {
                clearInterval(codingTimerInterval);
                codingTimerInterval = null;
            }
            
            // Stop all media streams
            if (verificationStream) {
                verificationStream.getTracks().forEach(track => track.stop());
                console.log('Released verification stream');
            }
            
            // Stop proctoring streams (both old format and new array format)
            if (window.proctoringStream1) {
                window.proctoringStream1.getTracks().forEach(track => track.stop());
                console.log('Released proctoring stream 1');
            }
            
            if (window.proctoringStream2) {
                window.proctoringStream2.getTracks().forEach(track => track.stop());
                console.log('Released proctoring stream 2');
            }
            
            // Stop proctoring streams from array (browser camera feeds)
            if (window._proctoringStreams && Array.isArray(window._proctoringStreams)) {
                window._proctoringStreams.forEach((stream, index) => {
                    if (stream && stream.getTracks) {
                        stream.getTracks().forEach(track => track.stop());
                        console.log(`Released proctoring stream ${index + 1} from array`);
                    }
                });
                window._proctoringStreams = [];
            }
            
            // Clear proctoring intervals
            if (window._proctoringIntervals && Array.isArray(window._proctoringIntervals)) {
                window._proctoringIntervals.forEach(interval => {
                    if (interval) clearInterval(interval);
                });
                window._proctoringIntervals = [];
            }
            
            // Stop media recorder
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                console.log('Stopped media recorder');
            }
            
            // Close audio context
            if (audioContext) {
                audioContext.close().catch(e => console.log('Audio context already closed'));
                console.log('Closed audio context');
            }
            
            // Clear all intervals and timeouts
            clearInterval(thinkingTimer);
            clearInterval(answeringTimer);
            clearInterval(reviewInterval);
            clearInterval(proctoringInterval);
            clearTimeout(noAnswerTimeout);
            clearInterval(terminationWarningInterval);
            
            // Release backend camera resources
            try {
                await fetch("{% url 'release_camera' %}", {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({ session_key: SESSION_KEY })
                });
                console.log('Backend camera resources released');
            } catch (error) {
                console.log('Error releasing backend camera:', error);
            }
            
            console.log('All media resources released successfully');
        } catch (error) {
            console.log('Error releasing media resources:', error);
        }
    }

        // Timestamp tracking for proctoring overlays
        let proctoringStartTime = Date.now();
        let timestampInterval = null;
        
        function updateProctoringTimestamps() {
            const elapsed = Math.floor((Date.now() - proctoringStartTime) / 1000);
            const hours = Math.floor(elapsed / 3600);
            const minutes = Math.floor((elapsed % 3600) / 60);
            const seconds = elapsed % 60;
            const timeString = `${String(hours).padStart(2, '0')}:${String(minutes).padStart(2, '0')}:${String(seconds).padStart(2, '0')}`;
            
            const timestampTech = document.getElementById('timestamp-overlay-tech');
            const timestampCoding = document.getElementById('timestamp-overlay-coding');
            if (timestampTech) timestampTech.textContent = timeString;
            if (timestampCoding) timestampCoding.textContent = timeString;
        }
        
        // Start timestamp updates
        function startProctoringTimestamps() {
            proctoringStartTime = Date.now();
            if (timestampInterval) clearInterval(timestampInterval);
            timestampInterval = setInterval(updateProctoringTimestamps, 1000);
            updateProctoringTimestamps(); // Initial update
        }
        
        function startProctoringMonitors() {
        // Clear any existing interval to avoid duplicates
        if (proctoringInterval) {
            clearInterval(proctoringInterval);
            proctoringInterval = null;
        }
        
        const proctoringFeed = document.getElementById('proctoring-feed');
        const proctoringFeed2 = document.getElementById('proctoring-feed-2');
        
        // Check if browser camera should be used (e.g., on cloud servers like Render)
        const useBrowserCamera = window.USE_BROWSER_CAMERA === true;
        
        if (useBrowserCamera) {
            console.log("üåê Starting proctoring monitors using browser camera (getUserMedia)...");
        } else {
            console.log("üì∫ Starting proctoring monitors via backend video_frame...");
        }
        
        // Update session ID displays
        if (SESSION_KEY) {
            const sessionIdTech = document.getElementById('proctoring-session-id-tech');
            const sessionIdCoding = document.getElementById('proctoring-session-id-coding');
            const sessionIdDisplay = SESSION_KEY.length > 8 ? SESSION_KEY.substring(0, 8) : SESSION_KEY;
            if (sessionIdTech) sessionIdTech.textContent = sessionIdDisplay;
            if (sessionIdCoding) sessionIdCoding.textContent = sessionIdDisplay;
        }
        
        // Function to start browser camera feed
        const startBrowserFeed = (imgElement, name) => {
            if (!imgElement) {
                console.error(`‚ùå ${name} image element not found`);
                return;
            }
            
            console.log(`üåê Starting ${name} live camera feed using browser camera...`);
            
            // Request browser camera access
            navigator.mediaDevices.getUserMedia({ 
                video: { 
                    width: { ideal: 640 },
                    height: { ideal: 480 },
                    facingMode: 'user'
                },
                audio: false 
            })
            .then(stream => {
                console.log(`‚úÖ Browser camera access granted for ${name}`);
                
                // Create a hidden video element to capture frames
                let videoEl = document.getElementById(`proctoring-video-${name.toLowerCase().replace(/\s+/g, '-')}`);
                if (!videoEl) {
                    videoEl = document.createElement('video');
                    videoEl.id = `proctoring-video-${name.toLowerCase().replace(/\s+/g, '-')}`;
                    videoEl.style.display = 'none';
                    videoEl.autoplay = true;
                    videoEl.playsInline = true;
                    document.body.appendChild(videoEl);
                }
                
                videoEl.srcObject = stream;
                videoEl.onloadedmetadata = () => {
                    videoEl.play();
                    
                    // Create canvas to capture frames and display in img element
                    let canvasEl = document.getElementById(`proctoring-canvas-${name.toLowerCase().replace(/\s+/g, '-')}`);
                    if (!canvasEl) {
                        canvasEl = document.createElement('canvas');
                        canvasEl.id = `proctoring-canvas-${name.toLowerCase().replace(/\s+/g, '-')}`;
                        canvasEl.style.display = 'none';
                        document.body.appendChild(canvasEl);
                    }
                    
                    canvasEl.width = videoEl.videoWidth || 640;
                    canvasEl.height = videoEl.videoHeight || 480;
                    
                    // Update img element with frames from video
                    const updateFrame = () => {
                        if (interviewEnded) {
                            stream.getTracks().forEach(track => track.stop());
                            return;
                        }
                        
                        const ctx = canvasEl.getContext('2d');
                        ctx.drawImage(videoEl, 0, 0, canvasEl.width, canvasEl.height);
                        imgElement.src = canvasEl.toDataURL('image/jpeg', 0.8);
                        imgElement.style.display = 'block';
                        imgElement.style.opacity = '1';
                        imgElement.style.backgroundColor = 'transparent';
                        
                        requestAnimationFrame(updateFrame);
                    };
                    
                    updateFrame();
                    console.log(`‚úÖ ${name} browser camera feed started`);
                };
                
                // Store stream for cleanup
                if (!window._proctoringStreams) window._proctoringStreams = [];
                window._proctoringStreams.push(stream);
            })
            .catch(error => {
                console.error(`‚ùå Error accessing browser camera for ${name}:`, error);
                imgElement.style.backgroundColor = '#000';
                // Fallback to backend feed if browser camera fails
                startBackendFeed(imgElement, name);
            });
        };
        
        // Function to start backend feed (fallback or when server has camera)
        const startBackendFeed = (imgElement, name, canvasId = null) => {
            if (!imgElement) {
                console.error(`‚ùå ${name} image element not found`);
                return;
            }
            
            console.log(`üì∫ Starting ${name} live camera feed (backend video_frame endpoint)...`);
            
            // Use same approach as identity verification - direct video_frame polling
            const frameUrl = `{% url 'video_frame' %}?session_key=${SESSION_KEY}`;
            let frameUpdateInterval = null;
            
            const updateFrame = () => {
                if (interviewEnded) {
                    if (frameUpdateInterval) clearInterval(frameUpdateInterval);
                    return;
                }
                
                const url = `${frameUrl}&t=${Date.now()}&cache=${Math.random()}`;
                imgElement.onload = () => {
                    // Frame loaded successfully
                    imgElement.style.opacity = '1';
                    imgElement.style.backgroundColor = 'transparent';
                };
                imgElement.onerror = () => {
                    // Silently continue - might be temporary network issue
                    imgElement.style.backgroundColor = '#000';
                };
                imgElement.src = url;
                imgElement.style.display = 'block';
                imgElement.style.opacity = '0.9';
            };
            
            // Poll every 500ms (~2fps - same as identity verification, sufficient for live monitoring)
            frameUpdateInterval = setInterval(updateFrame, 500);
            updateFrame(); // Start immediately
            
            console.log(`‚úÖ ${name} live camera feed started (backend video_frame endpoint)`);
            
            // Store interval for cleanup
            if (!window._proctoringIntervals) window._proctoringIntervals = [];
            window._proctoringIntervals.push(frameUpdateInterval);
        };
        
        // Start feeds based on camera availability
        if (useBrowserCamera) {
            startBrowserFeed(proctoringFeed, 'Technical Interview');
            startBrowserFeed(proctoringFeed2, 'Coding Round');
        } else {
        startBackendFeed(proctoringFeed, 'Technical Interview', 'proctoring-feed-canvas');
        startBackendFeed(proctoringFeed2, 'Coding Round', 'proctoring-feed-canvas-2');
        }
        
        // Start timestamp updates when proctoring starts
        startProctoringTimestamps();

        // Set a timeout to start interview even if proctoring feed doesn't load
        setTimeout(() => {
            if (document.getElementById('spoken-interview-phase').style.display !== 'none') {
                if (!PROCTOR_ONLY) {
                    console.log("Proctoring feed timeout - starting interview anyway");
                    startFirstSpokenQuestion();
                } else {
                    console.log("Proctor-only mode; skipping auto-start of spoken questions after timeout.");
                }
            }
        }, 10000);

        proctoringInterval = setInterval(async () => {
            if(interviewEnded) {
                clearInterval(proctoringInterval);
                return;
            }
            
            // Check which phase is visible - update warnings for active phase
            const spokenPhase = document.getElementById('spoken-interview-phase');
            const codingPhase = document.getElementById('coding-interview-phase');
            const isSpokenVisible = spokenPhase && spokenPhase.style.display !== 'none' && spokenPhase.style.display !== '';
            const isCodingVisible = codingPhase && codingPhase.style.display !== 'none' && codingPhase.style.display !== '';
            
            if (!isSpokenVisible && !isCodingVisible) {
                return; // No active phase
            }
            
            try {
                // Fetch warnings with timeout to prevent hanging
                const controller = new AbortController();
                let timeoutId;
                try {
                    timeoutId = setTimeout(() => {
                        if (!controller.signal.aborted) {
                            controller.abort();
                        }
                    }, 2000); // 2 second timeout
                    
                    const res = await fetch(`{% url 'get_proctoring_status' %}?session_key=${SESSION_KEY}&t=${Date.now()}`, {
                        signal: controller.signal
                    });
                    
                    if (timeoutId) clearTimeout(timeoutId);
                    
                    if (!res.ok) {
                        console.error('‚ùå Failed to fetch proctoring status:', res.status);
                        return;
                    }
                    const warnings = await res.json();
                    console.log('üìä Warnings received:', warnings); // Debug: log all warnings
                    
                    // Debounce absence warning - require it to be true for 2 consecutive checks (3 seconds total)
                    // This prevents rapid on/off flickering
                    if (!window._lastAbsenceState) window._lastAbsenceState = false;
                    if (!window._absenceCheckCount) window._absenceCheckCount = 0;
                    
                    if (warnings.no_person_warning_active) {
                        // Absence detected - increment counter
                        if (!window._lastAbsenceState) {
                            // Just became true - start counting
                            window._absenceCheckCount = 1;
                        } else {
                            // Still true - increment
                            window._absenceCheckCount++;
                        }
                        // Only show warning after 2 consecutive true checks (3 seconds)
                        if (window._absenceCheckCount >= 2) {
                            showTerminationWarning();
                        }
                    } else {
                        // Person present - reset counter and hide warning immediately
                        window._absenceCheckCount = 0;
                        hideTerminationWarning();
                    }
                    window._lastAbsenceState = warnings.no_person_warning_active;
                    
                    const list = document.getElementById('warnings-list');
                    const list2 = document.getElementById('warnings-list-2');
                    
                    // Always clear and update both lists if elements exist - ensure fresh update
                    if (list && isSpokenVisible) list.innerHTML = '';
                    if (list2 && isCodingVisible) list2.innerHTML = '';
                    let warningCount = 0;
                    // FRIENDLY NAMES MAP
                    const warningFriendlyMap = {
                      'no_person_warning_active': 'No Person Detected (Termination)',
                      'multiple_people': 'Multiple People Detected',
                      'phone_detected': 'Phone Detected',
                      'no_person': 'No Person in Frame',
                      'low_concentration': 'Low Concentration',
                      'tab_switched': 'Browser Tab Switched',
                      'excessive_noise': 'Excessive Noise',
                      'multiple_speakers': 'Multiple Speakers Detected'
                    };
                    for (const [key, value] of Object.entries(warnings)) {
                        if (value === true && (
                            key.endsWith('_warning') || 
                            key === 'multiple_people' ||
                            key === 'phone_detected' ||
                            key === 'no_person' ||
                            key === 'low_concentration' ||
                            key === 'tab_switched' ||
                            key === 'excessive_noise' ||
                            key === 'multiple_speakers')) {
                            const li = document.createElement('li');
                            li.textContent = warningFriendlyMap[key] || key.replace(/_/g, ' ').toUpperCase();
                            li.style.backgroundColor = '#dc3545';
                            li.style.color = 'white';
                            li.style.padding = '0.75rem 1.5rem';
                            li.style.borderRadius = '25px';
                            li.style.marginBottom = '0.75rem';
                            li.style.textAlign = 'center';
                            li.style.fontWeight = '600';
                            li.style.fontSize = '0.9rem';
                            // Always add to both lists if they exist (for visibility)
                            if (list && isSpokenVisible) {
                                list.appendChild(li.cloneNode(true));
                                console.log(`‚ö†Ô∏è Warning added to technical list: ${warningFriendlyMap[key]}`);
                            }
                            if (list2 && isCodingVisible) {
                                list2.appendChild(li.cloneNode(true));
                                console.log(`‚ö†Ô∏è Warning added to coding list: ${warningFriendlyMap[key]}`);
                            }
                            warningCount++;
                        }
                    }
                    // Log warning count for debugging
                    if (warningCount > 0) {
                        console.log(`üìä Total warnings displayed: ${warningCount} (Technical: ${isSpokenVisible}, Coding: ${isCodingVisible})`);
                    }
                } catch (fetchError) {
                    // Handle AbortError gracefully - just skip this iteration
                    if (fetchError.name === 'AbortError') {
                        // Request timed out or was aborted - skip silently
                        return;
                    }
                    throw fetchError; // Re-throw other errors
                } finally {
                    if (timeoutId) clearTimeout(timeoutId);
                }
            } catch (e) {
                // Only log non-AbortError exceptions
                if (e.name !== 'AbortError') {
                    console.error('‚ùå Error in proctoring interval:', e);
                }
            }
        }, 4000); // Check every 4 seconds to reduce load and prevent lag (increased from 3s)
        document.getElementById('done-btn')?.addEventListener('click', moveToReviewPhase);
    }


    function showTerminationWarning() {
        if (isTerminationWarningVisible || interviewEnded) return;
        isTerminationWarningVisible = true;
        document.getElementById('termination-modal').style.display = 'flex';
        let timeLeft = TERMINATION_TIME;
        const timer = document.getElementById('termination-modal').querySelector('.timer-display');
        terminationWarningInterval = setInterval(() => {
            timer.innerText = `Terminating in: ${formatTime(timeLeft)}`;
            timeLeft--;
            if (timeLeft < 0) endSpokenOnlyInterview();
        }, 1000);
    }

    function hideTerminationWarning() {
        if (!isTerminationWarningVisible) return;
        isTerminationWarningVisible = false;
        clearInterval(terminationWarningInterval);
        document.getElementById('termination-modal').style.display = 'none';
    }

    function formatTime(s) {
        if (s < 0) s = 0;
        const m = Math.floor(s / 60); s %= 60;
        return `${m.toString().padStart(2, '0')}:${s.toString().padStart(2, '0')}`;
    }
</script>
</body>
</html>